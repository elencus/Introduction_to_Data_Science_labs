{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f111f65-50b3-4a82-9787-259bff1c38fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca371f6b75cae0ae2d517b2f26c340c1",
     "grade": false,
     "grade_id": "cell-54161b7c1656278e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Laboratory Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7bc60f-1f11-4061-b23b-787946019e73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13a601e32f491d8fa278bd8ccdb88ddd",
     "grade": false,
     "grade_id": "cell-0231f0ce29809e3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this assignment, you will use the `movies.csv` dataset to build a neural network that predicts the genre of a movie from its features. After completing the classification task, you will apply clustering techniques to the dataset without the genre column to analyze how movies are grouped based on similarity and to compare these clusters with the original genre labels.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- Some parts of the code are already provided. **Do not modify the existing code.**\n",
    "- Write your solution only in the sections marked with `### YOUR SOLUTION`.\n",
    "- You can verify automatically graded tasks using the cell labeled `### TEST` after each function.\n",
    "\n",
    "***IMPORTANT NOTE:***\n",
    "- Name your Jupyter Notebook as `lab_ex_4_{index}.ipynb`.\n",
    "- For example, if your index is 123456, you should name your notebook as `lab_ex_2_12346.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0fe7fb-c987-4a04-aabc-a1aebd09426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp310-cp310-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\tales\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\tales\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.10.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tales\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tales\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading torch-2.9.1-cp310-cp310-win_amd64.whl (111.0 MB)\n",
      "   ---------------------------------------- 0.0/111.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/111.0 MB 8.2 MB/s eta 0:00:14\n",
      "    --------------------------------------- 1.6/111.0 MB 6.0 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 2.9/111.0 MB 5.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 3.9/111.0 MB 5.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 5.0/111.0 MB 5.7 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 5.8/111.0 MB 5.1 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 6.3/111.0 MB 5.0 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 7.3/111.0 MB 4.8 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 7.9/111.0 MB 4.6 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 8.7/111.0 MB 4.5 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 8.9/111.0 MB 4.5 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 9.4/111.0 MB 4.2 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 10.2/111.0 MB 4.2 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 11.5/111.0 MB 4.2 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 12.3/111.0 MB 4.2 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 13.6/111.0 MB 4.3 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 14.4/111.0 MB 4.3 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 15.2/111.0 MB 4.3 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 16.5/111.0 MB 4.4 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 17.3/111.0 MB 4.4 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 18.4/111.0 MB 4.5 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 18.6/111.0 MB 4.4 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 19.7/111.0 MB 4.3 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 20.2/111.0 MB 4.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 20.2/111.0 MB 4.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 21.0/111.0 MB 4.1 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 21.8/111.0 MB 4.1 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 22.5/111.0 MB 4.1 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 23.1/111.0 MB 4.0 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 23.9/111.0 MB 4.0 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 24.6/111.0 MB 4.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 25.4/111.0 MB 4.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 26.2/111.0 MB 4.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 27.0/111.0 MB 4.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 27.5/111.0 MB 4.0 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 27.8/111.0 MB 4.0 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 28.6/111.0 MB 3.9 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 29.6/111.0 MB 3.9 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 30.4/111.0 MB 3.9 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 31.5/111.0 MB 3.9 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 32.5/111.0 MB 4.0 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 33.6/111.0 MB 4.0 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 34.9/111.0 MB 4.1 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 35.7/111.0 MB 4.1 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 36.7/111.0 MB 4.1 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 37.7/111.0 MB 4.1 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 38.8/111.0 MB 4.1 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 39.8/111.0 MB 4.2 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 40.6/111.0 MB 4.2 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 41.4/111.0 MB 4.2 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 42.7/111.0 MB 4.2 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 43.8/111.0 MB 4.2 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 44.8/111.0 MB 4.2 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 46.1/111.0 MB 4.3 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 46.7/111.0 MB 4.2 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 47.7/111.0 MB 4.2 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 48.2/111.0 MB 4.2 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 48.8/111.0 MB 4.2 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 49.8/111.0 MB 4.2 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 50.9/111.0 MB 4.2 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 51.6/111.0 MB 4.2 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 52.7/111.0 MB 4.2 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 53.5/111.0 MB 4.2 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 54.3/111.0 MB 4.2 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 55.3/111.0 MB 4.2 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 56.4/111.0 MB 4.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.4/111.0 MB 4.3 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 58.5/111.0 MB 4.3 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 59.5/111.0 MB 4.3 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 60.3/111.0 MB 4.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 61.1/111.0 MB 4.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 61.6/111.0 MB 4.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 62.7/111.0 MB 4.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 63.7/111.0 MB 4.3 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 64.7/111.0 MB 4.3 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 65.3/111.0 MB 4.3 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 66.1/111.0 MB 4.3 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 67.1/111.0 MB 4.3 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 67.9/111.0 MB 4.3 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 68.4/111.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 69.2/111.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 70.3/111.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 71.0/111.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 71.8/111.0 MB 4.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 72.4/111.0 MB 4.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 73.4/111.0 MB 4.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 74.2/111.0 MB 4.3 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 75.2/111.0 MB 4.3 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 75.8/111.0 MB 4.2 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 76.5/111.0 MB 4.2 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 77.6/111.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 78.4/111.0 MB 4.3 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 79.7/111.0 MB 4.3 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 80.5/111.0 MB 4.3 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 81.3/111.0 MB 4.3 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 82.3/111.0 MB 4.3 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 82.8/111.0 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 83.6/111.0 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 84.7/111.0 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 85.2/111.0 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 86.0/111.0 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 87.0/111.0 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 87.3/111.0 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 88.1/111.0 MB 4.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 88.9/111.0 MB 4.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 89.7/111.0 MB 4.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 90.2/111.0 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 91.0/111.0 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 91.5/111.0 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 92.3/111.0 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 92.8/111.0 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 93.6/111.0 MB 4.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 94.4/111.0 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 95.2/111.0 MB 4.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 95.9/111.0 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 97.0/111.0 MB 4.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 98.0/111.0 MB 4.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 99.4/111.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 100.1/111.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 100.9/111.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 102.0/111.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 102.8/111.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 103.5/111.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 104.3/111.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 104.9/111.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 105.1/111.0 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 105.6/111.0 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 105.9/111.0 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 106.2/111.0 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 106.7/111.0 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 107.0/111.0 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 107.2/111.0 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 107.5/111.0 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 107.7/111.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.8/111.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.3/111.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.6/111.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.6/111.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.6/111.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/111.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/111.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/111.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 111.0/111.0 MB 3.9 MB/s  0:00:28\n",
      "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 1.6 MB/s  0:00:01\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.3 MB 1.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.5/6.3 MB 1.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 1.1 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 1.3/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.1/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 2.4/6.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 2.9/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.1/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 3.4/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 3.9/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 4.2/6.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 5.0/6.3 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 5.2/6.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.5/6.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 1.2 MB/s  0:00:05\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 1.3 MB/s  0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, torch\n",
      "\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [networkx]\n",
      "   ------------------------ --------------- 3/5 [fsspec]\n",
      "   ------------------------ --------------- 3/5 [fsspec]\n",
      "   ------------------------ --------------- 3/5 [fsspec]\n",
      "   ------------------------ --------------- 3/5 [fsspec]\n",
      "   ------------------------ --------------- 3/5 [fsspec]\n",
      "   ------------------------ --------------- 3/5 [fsspec]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   -------------------------------- ------- 4/5 [torch]\n",
      "   ---------------------------------------- 5/5 [torch]\n",
      "\n",
      "Successfully installed fsspec-2025.12.0 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d535d69-2a4c-41be-88df-0089c66444cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "044f85ed53900c4a4aaf3a4753c1ab52",
     "grade": false,
     "grade_id": "cell-b403ebf0859bee71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    adjusted_mutual_info_score,\n",
    "    homogeneity_score,\n",
    "    completeness_score,\n",
    "    v_measure_score\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c98809a-e159-4d7d-a1be-67b1ef06e70a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c0d448ab5242a29eb105b63a70fdc13",
     "grade": false,
     "grade_id": "cell-012002f75f4fe2b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hash_data_frame(df):\n",
    "    df_sorted = df.sort_index(axis=1).sort_values(by=list(df.columns))\n",
    "    return hashlib.sha256(pd.util.hash_pandas_object(df_sorted, index=True).values).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba50326e-d03e-4e60-839a-261852361dab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63b064862a366a732eebe33674a966d8",
     "grade": false,
     "grade_id": "cell-586d7c97e5770aee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hash_series(series):\n",
    "    series_str = \",\".join(map(str, series.values))\n",
    "    return hashlib.sha256(series_str.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5408e2d9-4d11-49fc-87ae-4e20305bb514",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0373fafcca64c2e5b49213fbb22f886",
     "grade": false,
     "grade_id": "cell-ea95fb632e0876d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hash_vocab(vocab):\n",
    "    items = sorted(vocab.items(), key=lambda x: x[1])  \n",
    "    vocab_str = \"\\n\".join(f\"{k}:{v}\" for k, v in items)\n",
    "    return hashlib.sha256(vocab_str.encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3443f3f3-4549-48c9-999c-36a3bfb0dd66",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84a0f8cc03425dfc40ce5595653ba77f",
     "grade": false,
     "grade_id": "cell-6bcb11118fc212f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hash_sequences(sequences):\n",
    "    flat = []\n",
    "    for seq in sequences:\n",
    "        flat.extend(seq)\n",
    "        flat.append(-1)  # separator to preserve sequence boundaries\n",
    "    return hashlib.sha256(str(flat).encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c780bf-d2fe-44ff-8acd-adaa0f624b9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72ccb9ba436a78159433a51c331e72da",
     "grade": false,
     "grade_id": "cell-c7fb64ba205a2cee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hash_tensor(tensor):\n",
    "    return hashlib.sha256(tensor.cpu().numpy().tobytes()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86a824e-9da9-4398-abd0-fb9f547d6860",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72c1c3a267a84208a00ab1e0549100bb",
     "grade": false,
     "grade_id": "cell-2f7ba392b314c24a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hash_number(x):\n",
    "    return hashlib.sha256(str(x).encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03fb7e35-2f3c-416e-be42-6c7e3d2b77a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b1c1b4277b50d7158dd5ba75320c976",
     "grade": false,
     "grade_id": "cell-ad7c30f9b92b7586",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12416</th>\n",
       "      <td>1995</td>\n",
       "      <td>Dolores Claiborne</td>\n",
       "      <td>American</td>\n",
       "      <td>Taylor Hackford</td>\n",
       "      <td>Kathy Bates, Jennifer Jason Leigh, David Strat...</td>\n",
       "      <td>crime drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dolores_Claiborn...</td>\n",
       "      <td>In 1995, Dolores Claiborne works as a domestic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year              Title Origin/Ethnicity         Director  \\\n",
       "12416          1995  Dolores Claiborne         American  Taylor Hackford   \n",
       "\n",
       "                                                    Cast        Genre  \\\n",
       "12416  Kathy Bates, Jennifer Jason Leigh, David Strat...  crime drama   \n",
       "\n",
       "                                               Wiki Page  \\\n",
       "12416  https://en.wikipedia.org/wiki/Dolores_Claiborn...   \n",
       "\n",
       "                                                    Plot  \n",
       "12416  In 1995, Dolores Claiborne works as a domestic...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"movies.csv\")\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed13ec3c-5805-4f8f-9bdd-302197fb58e0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "caf894ba6d2d919c7cf5bd9a13aff2a4",
     "grade": false,
     "grade_id": "cell-4e0e4912473904b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def filter_genres(df, genres):\n",
    "    \"\"\"\n",
    "    Filters the dataset to include only movies belonging to the specified\n",
    "    genres and ensures that the resulting DataFrame has a sequential index.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Movie dataset containing a 'Genre' column\n",
    "    genres (list): Genres to retain\n",
    "\n",
    "    Return the result as a `pd.DataFrame`.\n",
    "    \"\"\"\n",
    "    filtered = df[df[\"Genre\"].isin(genres)].copy()\n",
    "    filtered = filtered.reset_index(drop=True)\n",
    "    return filtered\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c45b60-6648-4eb1-b50d-da64814b2670",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13d85c7f36c9e3c7cae097f6bd27373d",
     "grade": false,
     "grade_id": "cell-7f80c3a6026eb531",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = filter_genres(df, [\"comedy\", \"drama\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7a38c9-3eac-4daa-a18f-8d2872148c2f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "737c7a168abbc9339e719aa6adcebc26",
     "grade": true,
     "grade_id": "cell-3d3316cb7d34ec58",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST\n",
    "_df = pd.read_csv(\"movies.csv\")\n",
    "_df = filter_genres(_df, [\"comedy\", \"drama\"])\n",
    "assert hash_data_frame(_df) == \"edad962d401b26a758e9cfb7097272c25c68339782ddb87e9bb04558d5f72c26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb2cd41-c793-4534-b177-b6ae9d075cd9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e19d7205ab9ca4298f24c96f4ada4ba",
     "grade": true,
     "grade_id": "cell-968473939bca833e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### MANUALLY GRADED TASK\n",
    "def movie_plot_word_counts(df):\n",
    "    \"\"\"\n",
    "    Creates a plot that shows the number of words in the movie plot descriptions.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    plot = df[\"Plot\"].dropna().astype(str)\n",
    "    words = plot.apply(lambda x: len(x.split()))\n",
    "    \n",
    "    plt.hist(words, bins=50)\n",
    "    return plt.show()\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2524a34b-55d8-47cd-8542-c8369fdbf4b6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b488ab676038190e54dbb55a054f4c1",
     "grade": false,
     "grade_id": "cell-4e2f557b6c09dbe5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_plot_word_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cf9de64-2734-4929-bbcd-09242304233f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01833cd28bcad85dc399bc017de8de15",
     "grade": false,
     "grade_id": "cell-dfdfc889f5099f04",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def preprocess_plot(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the 'Plot' column by converting all text to lowercase and removing the plots \n",
    "    containing more than 1000 words and ensure that the resulting DataFrame has a sequential index. \n",
    "\n",
    "    Returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    newData = df.copy()\n",
    "    newData[\"Plot\"] = newData[\"Plot\"].astype(str).str.lower()\n",
    "    words = newData[\"Plot\"].apply(lambda x: len(x.split()))\n",
    "    newData = newData[words <= 1000].copy()\n",
    "\n",
    "    newData = newData.reset_index(drop=True)\n",
    "    return newData\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5dcf559-ff26-44c3-8178-c79209c74d95",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "594faa926f58af7b884390d6bf408f20",
     "grade": false,
     "grade_id": "cell-3b9d2fab64c44fa1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = preprocess_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d43bef59-d3ed-4e31-a6c1-bcee3a3e0f70",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b33bf0af81dea25a9165ca18573809d",
     "grade": true,
     "grade_id": "cell-857d0bc67016d7cb",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST\n",
    "_df = pd.read_csv(\"movies.csv\")\n",
    "_df = preprocess_plot(_df)\n",
    "assert hash_data_frame(_df) == \"d960d3d487ec47f0b5ba182b7bc602b63db9c15a1e16076cdf78f60abc4164ef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e41164b9-04ec-4763-8d3a-7b9a6838511e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "444831fc7452089d4a99f85561531f0c",
     "grade": false,
     "grade_id": "cell-fe6b27b6095ba621",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def partition_dataset(df):\n",
    "    \"\"\"\n",
    "    Split the dataset into features (X) and target (y), where the feature used is `Plot` and the target is `Genre`.\n",
    "    Then, divide X and y into training, validation and test sets using an 80:20 ratio.\n",
    "\n",
    "    If you think encoding is necessary use df[column].astype(\"category\").cat.codes\n",
    "\n",
    "    Use `random_state=42` to ensure reproducibility.\n",
    "    \n",
    "    Return the sets in the following order: train_X, val_X, test_X, train_y, val_y, test_y.\n",
    "    \"\"\"\n",
    "    X = df[\"Plot\"]\n",
    "    y = df[\"Genre\"].astype(\"category\").cat.codes\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    train_X, val_X, train_y, val_y = train_test_split(\n",
    "        train_X, train_y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return train_X, val_X, test_X, train_y, val_y, test_y\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "671ad3fc-be9b-487d-84a4-1eb167e2e1b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23cfa8ba0ca5dcc899e850fd540957a9",
     "grade": false,
     "grade_id": "cell-d7422721024bb0bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_X, val_X, test_X, train_y, val_y, test_y = partition_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf389007-161a-4c24-8b44-f0e515d98a55",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fb315b19c8bd1185cf0fd739cbfacfa",
     "grade": true,
     "grade_id": "cell-73ff2e722c0e60f1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## TEST\n",
    "_df = pd.read_csv(\"movies.csv\")\n",
    "_train_X, _val_X, _test_X, _train_y, _val_y, _test_y = partition_dataset(_df)\n",
    "assert hash_series(_train_X) == \"f3f633cca3a7d238c602554f410241506f3dbb31513295c73bd76b77ff9bd34d\"\n",
    "assert hash_series(_val_X) == \"a66099bd3b1843b84f4597741f49550d258b1b41c2a7aa692a52d32e132ceb85\"\n",
    "assert hash_series(_test_X) == \"6ac1e882e03259be257de0c476af663e73286d3718800b0e11760485da25d332\"\n",
    "assert hash_series(_train_y) == \"bb48348267767da5f6eba35c97ee91b0d636f20d87b7603a370f7284d06ada64\"\n",
    "assert hash_series(_val_y) == \"146395270412839a91e034b3e6a7259f083284314818b6a02fd1a5aeb1524a1b\"\n",
    "assert hash_series(_test_y) == \"8e0a6892cc3b60babc4e713216551a3010708a404f1f8cb2ecd47fd48c8eeaaa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98604905-6759-4bb1-bce9-9ec614ae16ac",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e445c13b729742465627c964ffd62b9",
     "grade": false,
     "grade_id": "cell-0c09350f9e82565d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def build_vocab(texts, max_vocab_size):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary dictionary from a list of text strings.\n",
    "\n",
    "    The function should count word frequencies across all input texts and\n",
    "    assign an integer index to each word. The vocabulary must include the\n",
    "    special tokens \"<PAD>\" with index 0 and \"<OOV>\" with index 1. The remaining\n",
    "    words should be added in descending order of frequency, up to the maximum\n",
    "    vocabulary size.\n",
    "\n",
    "    Parameters:\n",
    "    texts (list of str): List of preprocessed text strings\n",
    "    max_vocab_size (int): Maximum size of the vocabulary, including special\n",
    "                          tokens\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary mapping words to integer indices\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "\n",
    "    for sentence in texts:\n",
    "        counter.update(sentence.split())\n",
    "\n",
    "    vocab = {\n",
    "        \"<PAD>\": 0,\n",
    "        \"<OOV>\": 1\n",
    "    }\n",
    "\n",
    "    for idx, (word, _) in enumerate(\n",
    "        counter.most_common(max_vocab_size - 2), start=2\n",
    "    ):\n",
    "        vocab[word] = idx\n",
    "\n",
    "    return vocab\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "447589c4-b7b3-408c-b5d6-b031bcc01a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab6df7b8e4bbaa59c1ee38b40a82d12c",
     "grade": false,
     "grade_id": "cell-256e53fbe48b8764",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "vocab = build_vocab(train_X.values, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a3d097c-a717-4445-b61e-9bc287f94e71",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37d18ff79dbfbc0c4bb46050cd87de4b",
     "grade": true,
     "grade_id": "cell-269c56165d42a175",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## TEST\n",
    "assert hash_vocab(vocab) == \"cb5e3c6b40506bc7e0aa34474d58a04733b16b4408739ede5cb41812a0d2279e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a635500b-cc45-4435-b317-fa664806f41f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80fd8e9cfa088e76eb48cf3d5fee7cb1",
     "grade": false,
     "grade_id": "cell-4799c3bd39175c86",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def texts_to_sequences(texts, vocab):\n",
    "    \"\"\"\n",
    "    Converts a list of text strings into sequences of integer indices using a\n",
    "    given vocabulary.\n",
    "\n",
    "    Each word in a text should be replaced by its corresponding index from the\n",
    "    vocabulary. Words that are not present in the vocabulary must be mapped to\n",
    "    the \"<OOV>\" token.\n",
    "\n",
    "    Parameters:\n",
    "    texts (list of str): List of preprocessed text strings\n",
    "    vocab (dict): Vocabulary mapping words to integer indices\n",
    "\n",
    "    Returns:\n",
    "    list of list of int: List of integer sequences corresponding to the input texts\n",
    "    \"\"\" \n",
    "    sequences = []\n",
    "    \n",
    "    for sentence in texts:\n",
    "        seq = [\n",
    "            vocab.get(word, vocab[\"<OOV>\"])\n",
    "            for word in sentence.split()\n",
    "        ]\n",
    "        sequences.append(seq)\n",
    "\n",
    "    return sequences\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1d2a587-4c38-4419-b6e8-e111d539cd50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5841cf7253143e975a0b705d1d3cce8b",
     "grade": false,
     "grade_id": "cell-e103204669048394",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_X = texts_to_sequences(train_X.values, vocab)\n",
    "val_X   = texts_to_sequences(val_X.values, vocab)\n",
    "test_X  = texts_to_sequences(test_X.values, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4994fd06-f5c8-4c29-8b50-adaac067653d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1c6b10227b246e22493d75e28b5461d",
     "grade": true,
     "grade_id": "cell-9fbc08c98b932e66",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##TEST\n",
    "assert hash_sequences(train_X) == \"0402e69472cc84e0564e02f3fbf556e58b01a6cc9a5a9c864db28d968ea1d649\"\n",
    "assert hash_sequences(val_X) == \"0b6c7bc470d2b19922835e3cc36f733a31a4389dae3cbb21572cd10327660bf7\"\n",
    "assert hash_sequences(test_X) == \"72706aedbae3b45831ca6b62966f6736dd69f1155d65dd8b1252e4a5655a74ed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f31df721-4634-4ca0-939f-16a8b8f25163",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4938f4e0d7a309f4da787fb6cc24fe8f",
     "grade": false,
     "grade_id": "cell-5bd7620919f91b67",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def pad(sequences, pad_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of integer sequences so that all sequences have the same length.\n",
    "\n",
    "    Shorter sequences should be padded with the specified padding value until\n",
    "    they match the length of the longest sequence. The output should be a\n",
    "    tensor suitable for batch processing in a neural network.\n",
    "\n",
    "    Parameters:\n",
    "    sequences (list of list of int): List of integer sequences\n",
    "    pad_value (int, optional): Value used for padding (default is 0)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Padded tensor of shape (batch_size, max_sequence_length)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return pad_sequence(\n",
    "        [torch.tensor(seq, dtype=torch.long) for seq in sequences],\n",
    "        batch_first=True,\n",
    "        padding_value=pad_value\n",
    "    )\n",
    "    raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af1cdd01-95f7-4c89-a512-a1ea8011bb6e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e2c552d81c4285e780b8aeb02044c78",
     "grade": false,
     "grade_id": "cell-fe30b24ea8c5d5e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_X = pad(train_X, pad_value=vocab[\"<PAD>\"])\n",
    "val_X   = pad(val_X,pad_value=vocab[\"<PAD>\"])\n",
    "test_X  = pad(test_X, pad_value=vocab[\"<PAD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c8b0a82-9fca-4061-9bec-13cc99c76e64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db25cfc1b0a3dc4981ed60538cfa757e",
     "grade": true,
     "grade_id": "cell-f125a36a8e60355f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##TEST \n",
    "assert hash_tensor(train_X) == \"a512664e689288d133c84a6f8033ee516b025abf6f2305a1fbcb3fd6238e040e\"\n",
    "assert hash_tensor(val_X) == \"933f4a3b2c14892052c211291e96b1c5d1e7691549452a485db89790158af032\"\n",
    "assert hash_tensor(test_X) == \"f44f54df5ada534b075b1dea85f3082bae7f0584001873e21891dc58de637373\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38542455-32a5-4243-a82e-642d3fc49000",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b44fa083bdfa43ffc0f01ab0183b80aa",
     "grade": false,
     "grade_id": "cell-483f7fead6bd23fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    CNNLSTM model for text classification.\n",
    "\n",
    "    The model should consist of the following components (in order):\n",
    "\n",
    "    1. embbedding: An embedding layer that maps token indices to 128-dimensional vectors.\n",
    "\n",
    "    2. conv1: A 1D convolutional layer with:\n",
    "       - 32 output channels\n",
    "       - kernel size of 4\n",
    "\n",
    "       This should be followed by a max-pooling layer with pool size 2.\n",
    "\n",
    "    3. conv2: A second 1D convolutional layer with:\n",
    "       - 64 output channels\n",
    "       - kernel size of 4\n",
    "       - appropriate padding\n",
    "\n",
    "       This should also be followed by a max-pooling layer with pool size 2.\n",
    "\n",
    "    4. Two LSTM layers:\n",
    "       - lstm1: The first LSTM takes the convolutional features as input and has\n",
    "         128 hidden units.\n",
    "       - lstm2: The second LSTM takes the output of the first LSTM and has\n",
    "         64 hidden units.\n",
    "\n",
    "    5. fc: A fully connected (linear) layer.\n",
    "\n",
    "    Hint:\n",
    "    Think carefully about the activation function needed and the number of\n",
    "    output neurons in the final layer. Do NOT apply an activation function in\n",
    "    the model. The activation will be handled later in the criterion.\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, 128, padding_idx=0)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(128, 32, kernel_size=4)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=4, padding=2)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.lstm1 = nn.LSTM(64, 128, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(128, 64, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)         \n",
    "        x = x.permute(0, 2, 1)         \n",
    "\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.permute(0, 2, 1)         \n",
    "\n",
    "        x, _ = self.lstm1(x)\n",
    "        _, (h, _) = self.lstm2(x)\n",
    "\n",
    "        return self.fc(h[-1])\n",
    "    # raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cb0f5e0-06a3-4e61-858a-4ccc5d341090",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "435a63be1acebca5c85b2f4cd8e02b20",
     "grade": false,
     "grade_id": "cell-1ddd904371bdba90",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def initialize_model():\n",
    "    \"\"\"\n",
    "    Initializes and returns a CNN-LSTM model for text classification.\n",
    "\n",
    "    Parameters:\n",
    "    vocab_size (int): Size of the vocabulary\n",
    "    num_classes (int): Number of output classes\n",
    "\n",
    "    Returns:\n",
    "    torch.nn.Module: Initialized CNN-LSTM model\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    vocab_size = len(vocab)\n",
    "    num_classes = 1\n",
    "    return CNN_LSTM(vocab_size, num_classes)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0af1bcbb-0480-46fe-a319-3945ad4adddd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10a818d54cab659e36bec4a82ffa2f73",
     "grade": false,
     "grade_id": "cell-79216dd297b336ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39fe1f29-95ee-4d39-bd82-6a824fc27c00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84ba949d6c232939bda8e47ace3385a6",
     "grade": true,
     "grade_id": "cell-66bd3031f3efe82c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "###TEST\n",
    "assert isinstance(model, nn.Module)\n",
    "assert hasattr(model, \"embedding\")\n",
    "assert model.embedding.embedding_dim == 128\n",
    "assert hasattr(model, \"conv1\")\n",
    "assert hasattr(model, \"conv2\")\n",
    "assert model.conv1.out_channels == 32\n",
    "assert model.conv2.out_channels == 64\n",
    "assert hasattr(model, \"lstm1\")\n",
    "assert hasattr(model, \"lstm2\")\n",
    "assert model.lstm1.hidden_size == 128\n",
    "assert model.lstm2.hidden_size == 64\n",
    "assert hasattr(model, \"fc\")\n",
    "assert hash_number(model.fc.out_features) == \"6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aff49454-c82f-4619-9dff-4c8b2b81a78c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83f1434931aeb22f76629ebd1fae4486",
     "grade": false,
     "grade_id": "cell-493dda8f1b7d4b44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_y = torch.tensor(train_y.values, dtype=torch.long)\n",
    "val_y   = torch.tensor(val_y.values, dtype=torch.long)\n",
    "test_y  = torch.tensor(test_y.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0d668a44-1aa1-499b-8419-b9dc6d0e42ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a647d479367d686510494983e7c0f160",
     "grade": false,
     "grade_id": "cell-f8e440b3ee8f948f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "# Define the optimizer and the loss function\n",
    "    # Hint:\n",
    "    # Since no activation function is defined at the output layer, you should choose\n",
    "    # a loss function suitable for this task that internally applies the appropriate\n",
    "    # activation.\n",
    "        \n",
    "# YOUR CODE HERE\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1457f3ab-45af-4a58-936a-b02a46501d64",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "163e3056d0869df24cc1a7cc7c5dc1ee",
     "grade": false,
     "grade_id": "cell-34ba948524f6c426",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def train_one_epoch(model, X, y, batch_size, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch using mini-batch gradient descent\n",
    "    \n",
    "    Returns:\n",
    "    float: Average training loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = X.shape[0]\n",
    "\n",
    "    for start in range(0, n, batch_size):\n",
    "        end = min(start + batch_size, n)\n",
    "        Xb = X[start:end]\n",
    "        yb = y[start:end].float().unsqueeze(1)   \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(Xb)                        \n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * (end - start)\n",
    "\n",
    "    return float(total_loss / n)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "670a963e-2dd6-4a02-aaa7-b44559d340a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68c427495f0ddfe4566bdadf336e95f1",
     "grade": false,
     "grade_id": "cell-c1f3b53c6a662882",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "loss = train_one_epoch(\n",
    "    model,\n",
    "    train_X[:64],\n",
    "    train_y[:64],\n",
    "    batch_size=32,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fda38887-5e5d-4ed5-ae6c-a9b9242aede2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2bbea54eeca1dd27fa3bd60978f2b08",
     "grade": true,
     "grade_id": "cell-7e689a64fd4ca156",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##TEST\n",
    "assert isinstance(loss, float)\n",
    "assert 0.4 < loss < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bf3040a7-1645-42be-a7f2-fd62ca4975e5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fa79f1343949fd5a29b10676d3c1170",
     "grade": false,
     "grade_id": "cell-cdbaaf9e91d5debf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def evaluate(model, X, y, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a given dataset.\n",
    "    Returns:\n",
    "    tuple: (loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)                         \n",
    "        y_true = y.float().unsqueeze(1)            \n",
    "\n",
    "        loss = criterion(logits, y_true).item()\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= 0.5).long().squeeze(1)   \n",
    "        acc = (preds == y.long()).float().mean().item()\n",
    "\n",
    "    return float(loss), float(acc)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "80bfa832-104b-47ab-b72e-c53b1bc46ed3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5e708f7f0f0551208bdeae933627ef2",
     "grade": false,
     "grade_id": "cell-eb9e48f804bbc6de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "val_loss, val_acc = evaluate(\n",
    "    model,\n",
    "    train_X[:64],\n",
    "    train_y[:64],\n",
    "    criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "320f3f16-637e-4cd1-b809-b89d0f36ef62",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b9cb5e32828bacf65237b518584bb7c",
     "grade": true,
     "grade_id": "cell-f9ee3628996517d1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##TEST\n",
    "assert isinstance(val_loss, float)\n",
    "assert isinstance(val_acc, float)\n",
    "assert 0.5 <= val_acc <= 1\n",
    "assert 0.5 <= val_loss <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c040aa9e-5686-4ecc-b8c7-3eb1a964a99c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "291c4e6d14149546130cfbe4bdb2ffca",
     "grade": false,
     "grade_id": "cell-75b0873c288daed9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, train_X, train_y, val_X, val_y,\n",
    "    epochs, batch_size, optimizer, criterion\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the model for multiple epochs and evaluates it after each epoch.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (train_losses, val_losses)\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(\n",
    "            model, train_X, train_y, batch_size, optimizer, criterion\n",
    "        )\n",
    "\n",
    "        val_loss, val_acc = evaluate(\n",
    "            model, val_X, val_y, criterion\n",
    "        )\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"Train loss: {train_loss:.4f} | \"\n",
    "            f\"Val loss: {val_loss:.4f} | \"\n",
    "            f\"Val acc: {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4abf696f-2322-4ad2-8b69-19bce27084ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fee90d22e2fb2c0bd2913655b91139b5",
     "grade": false,
     "grade_id": "cell-be67656f519da068",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train loss: 0.6474 | Val loss: 0.6399 | Val acc: 0.6406\n",
      "Epoch 2/100 | Train loss: 0.6390 | Val loss: 0.6345 | Val acc: 0.6406\n",
      "Epoch 3/100 | Train loss: 0.6343 | Val loss: 0.6289 | Val acc: 0.6406\n",
      "Epoch 4/100 | Train loss: 0.6285 | Val loss: 0.6236 | Val acc: 0.6406\n",
      "Epoch 5/100 | Train loss: 0.6236 | Val loss: 0.6193 | Val acc: 0.6406\n",
      "Epoch 6/100 | Train loss: 0.6194 | Val loss: 0.6148 | Val acc: 0.6406\n",
      "Epoch 7/100 | Train loss: 0.6148 | Val loss: 0.6098 | Val acc: 0.6406\n",
      "Epoch 8/100 | Train loss: 0.6098 | Val loss: 0.6045 | Val acc: 0.6406\n",
      "Epoch 9/100 | Train loss: 0.6045 | Val loss: 0.5988 | Val acc: 0.6406\n",
      "Epoch 10/100 | Train loss: 0.5987 | Val loss: 0.5923 | Val acc: 0.6406\n",
      "Epoch 11/100 | Train loss: 0.5920 | Val loss: 0.5848 | Val acc: 0.6406\n",
      "Epoch 12/100 | Train loss: 0.5843 | Val loss: 0.5765 | Val acc: 0.6406\n",
      "Epoch 13/100 | Train loss: 0.5760 | Val loss: 0.5677 | Val acc: 0.6406\n",
      "Epoch 14/100 | Train loss: 0.5674 | Val loss: 0.5587 | Val acc: 0.6406\n",
      "Epoch 15/100 | Train loss: 0.5587 | Val loss: 0.5494 | Val acc: 0.6406\n",
      "Epoch 16/100 | Train loss: 0.5501 | Val loss: 0.5404 | Val acc: 0.7188\n",
      "Epoch 17/100 | Train loss: 0.5421 | Val loss: 0.5302 | Val acc: 0.7344\n",
      "Epoch 18/100 | Train loss: 0.5313 | Val loss: 0.5136 | Val acc: 0.7656\n",
      "Epoch 19/100 | Train loss: 0.5138 | Val loss: 0.4985 | Val acc: 0.7969\n",
      "Epoch 20/100 | Train loss: 0.4926 | Val loss: 0.4934 | Val acc: 0.8125\n",
      "Epoch 21/100 | Train loss: 0.4910 | Val loss: 0.4902 | Val acc: 0.7969\n",
      "Epoch 22/100 | Train loss: 0.4866 | Val loss: 0.4874 | Val acc: 0.7344\n",
      "Epoch 23/100 | Train loss: 0.4846 | Val loss: 0.4730 | Val acc: 0.8125\n",
      "Epoch 24/100 | Train loss: 0.4700 | Val loss: 0.4589 | Val acc: 0.8750\n",
      "Epoch 25/100 | Train loss: 0.4565 | Val loss: 0.4465 | Val acc: 0.8906\n",
      "Epoch 26/100 | Train loss: 0.4440 | Val loss: 0.4337 | Val acc: 0.8906\n",
      "Epoch 27/100 | Train loss: 0.4304 | Val loss: 0.4197 | Val acc: 0.9062\n",
      "Epoch 28/100 | Train loss: 0.4158 | Val loss: 0.4023 | Val acc: 0.9062\n",
      "Epoch 29/100 | Train loss: 0.3976 | Val loss: 0.3833 | Val acc: 0.9062\n",
      "Epoch 30/100 | Train loss: 0.3865 | Val loss: 0.3577 | Val acc: 0.9531\n",
      "Epoch 31/100 | Train loss: 0.3513 | Val loss: 0.3358 | Val acc: 0.9531\n",
      "Epoch 32/100 | Train loss: 0.3315 | Val loss: 0.3174 | Val acc: 0.9531\n",
      "Epoch 33/100 | Train loss: 0.3089 | Val loss: 0.2329 | Val acc: 0.9688\n",
      "Epoch 34/100 | Train loss: 0.2305 | Val loss: 0.2233 | Val acc: 0.9688\n",
      "Epoch 35/100 | Train loss: 0.2194 | Val loss: 0.2169 | Val acc: 0.9688\n",
      "Epoch 36/100 | Train loss: 0.2157 | Val loss: 0.2130 | Val acc: 0.9688\n",
      "Epoch 37/100 | Train loss: 0.2118 | Val loss: 0.2090 | Val acc: 0.9688\n",
      "Epoch 38/100 | Train loss: 0.2078 | Val loss: 0.2049 | Val acc: 0.9688\n",
      "Epoch 39/100 | Train loss: 0.2035 | Val loss: 0.2012 | Val acc: 0.9688\n",
      "Epoch 40/100 | Train loss: 0.1999 | Val loss: 0.1975 | Val acc: 0.9688\n",
      "Epoch 41/100 | Train loss: 0.1962 | Val loss: 0.1931 | Val acc: 0.9688\n",
      "Epoch 42/100 | Train loss: 0.1917 | Val loss: 0.1894 | Val acc: 0.9688\n",
      "Epoch 43/100 | Train loss: 0.1885 | Val loss: 0.1864 | Val acc: 0.9688\n",
      "Epoch 44/100 | Train loss: 0.1855 | Val loss: 0.1838 | Val acc: 0.9688\n",
      "Epoch 45/100 | Train loss: 0.1829 | Val loss: 0.1814 | Val acc: 0.9688\n",
      "Epoch 46/100 | Train loss: 0.1806 | Val loss: 0.1792 | Val acc: 0.9688\n",
      "Epoch 47/100 | Train loss: 0.1784 | Val loss: 0.1771 | Val acc: 0.9688\n",
      "Epoch 48/100 | Train loss: 0.1763 | Val loss: 0.1750 | Val acc: 0.9688\n",
      "Epoch 49/100 | Train loss: 0.1743 | Val loss: 0.1731 | Val acc: 0.9688\n",
      "Epoch 50/100 | Train loss: 0.1725 | Val loss: 0.1713 | Val acc: 0.9688\n",
      "Epoch 51/100 | Train loss: 0.1707 | Val loss: 0.1696 | Val acc: 0.9688\n",
      "Epoch 52/100 | Train loss: 0.1690 | Val loss: 0.1680 | Val acc: 0.9688\n",
      "Epoch 53/100 | Train loss: 0.1675 | Val loss: 0.1665 | Val acc: 0.9688\n",
      "Epoch 54/100 | Train loss: 0.1659 | Val loss: 0.1650 | Val acc: 0.9688\n",
      "Epoch 55/100 | Train loss: 0.1645 | Val loss: 0.1636 | Val acc: 0.9688\n",
      "Epoch 56/100 | Train loss: 0.1631 | Val loss: 0.1622 | Val acc: 0.9688\n",
      "Epoch 57/100 | Train loss: 0.1617 | Val loss: 0.1608 | Val acc: 0.9688\n",
      "Epoch 58/100 | Train loss: 0.1604 | Val loss: 0.1595 | Val acc: 0.9688\n",
      "Epoch 59/100 | Train loss: 0.1591 | Val loss: 0.1583 | Val acc: 0.9688\n",
      "Epoch 60/100 | Train loss: 0.1579 | Val loss: 0.1571 | Val acc: 0.9688\n",
      "Epoch 61/100 | Train loss: 0.1567 | Val loss: 0.1560 | Val acc: 0.9688\n",
      "Epoch 62/100 | Train loss: 0.1556 | Val loss: 0.1549 | Val acc: 0.9688\n",
      "Epoch 63/100 | Train loss: 0.1545 | Val loss: 0.1538 | Val acc: 0.9688\n",
      "Epoch 64/100 | Train loss: 0.1535 | Val loss: 0.1528 | Val acc: 0.9688\n",
      "Epoch 65/100 | Train loss: 0.1525 | Val loss: 0.1518 | Val acc: 0.9688\n",
      "Epoch 66/100 | Train loss: 0.1515 | Val loss: 0.1508 | Val acc: 0.9688\n",
      "Epoch 67/100 | Train loss: 0.1505 | Val loss: 0.1499 | Val acc: 0.9688\n",
      "Epoch 68/100 | Train loss: 0.1496 | Val loss: 0.1489 | Val acc: 0.9688\n",
      "Epoch 69/100 | Train loss: 0.1486 | Val loss: 0.1480 | Val acc: 0.9688\n",
      "Epoch 70/100 | Train loss: 0.1477 | Val loss: 0.1472 | Val acc: 0.9688\n",
      "Epoch 71/100 | Train loss: 0.1469 | Val loss: 0.1463 | Val acc: 0.9688\n",
      "Epoch 72/100 | Train loss: 0.1461 | Val loss: 0.1455 | Val acc: 0.9688\n",
      "Epoch 73/100 | Train loss: 0.1453 | Val loss: 0.1447 | Val acc: 0.9688\n",
      "Epoch 74/100 | Train loss: 0.1445 | Val loss: 0.1440 | Val acc: 0.9688\n",
      "Epoch 75/100 | Train loss: 0.1437 | Val loss: 0.1432 | Val acc: 0.9688\n",
      "Epoch 76/100 | Train loss: 0.1430 | Val loss: 0.1425 | Val acc: 0.9688\n",
      "Epoch 77/100 | Train loss: 0.1423 | Val loss: 0.1417 | Val acc: 0.9688\n",
      "Epoch 78/100 | Train loss: 0.1415 | Val loss: 0.1410 | Val acc: 0.9688\n",
      "Epoch 79/100 | Train loss: 0.1408 | Val loss: 0.1403 | Val acc: 0.9688\n",
      "Epoch 80/100 | Train loss: 0.1401 | Val loss: 0.1397 | Val acc: 0.9688\n",
      "Epoch 81/100 | Train loss: 0.1395 | Val loss: 0.1390 | Val acc: 0.9688\n",
      "Epoch 82/100 | Train loss: 0.1388 | Val loss: 0.1383 | Val acc: 0.9688\n",
      "Epoch 83/100 | Train loss: 0.1382 | Val loss: 0.1377 | Val acc: 0.9688\n",
      "Epoch 84/100 | Train loss: 0.1375 | Val loss: 0.1371 | Val acc: 0.9688\n",
      "Epoch 85/100 | Train loss: 0.1369 | Val loss: 0.1364 | Val acc: 0.9688\n",
      "Epoch 86/100 | Train loss: 0.1363 | Val loss: 0.1358 | Val acc: 0.9688\n",
      "Epoch 87/100 | Train loss: 0.1357 | Val loss: 0.1352 | Val acc: 0.9688\n",
      "Epoch 88/100 | Train loss: 0.1351 | Val loss: 0.1346 | Val acc: 0.9688\n",
      "Epoch 89/100 | Train loss: 0.1345 | Val loss: 0.1340 | Val acc: 0.9688\n",
      "Epoch 90/100 | Train loss: 0.1339 | Val loss: 0.1334 | Val acc: 0.9688\n",
      "Epoch 91/100 | Train loss: 0.1333 | Val loss: 0.1328 | Val acc: 0.9688\n",
      "Epoch 92/100 | Train loss: 0.1327 | Val loss: 0.1322 | Val acc: 0.9688\n",
      "Epoch 93/100 | Train loss: 0.1321 | Val loss: 0.1317 | Val acc: 0.9688\n",
      "Epoch 94/100 | Train loss: 0.1315 | Val loss: 0.1311 | Val acc: 0.9688\n",
      "Epoch 95/100 | Train loss: 0.1310 | Val loss: 0.1305 | Val acc: 0.9688\n",
      "Epoch 96/100 | Train loss: 0.1304 | Val loss: 0.1299 | Val acc: 0.9688\n",
      "Epoch 97/100 | Train loss: 0.1298 | Val loss: 0.1294 | Val acc: 0.9688\n",
      "Epoch 98/100 | Train loss: 0.1293 | Val loss: 0.1288 | Val acc: 0.9688\n",
      "Epoch 99/100 | Train loss: 0.1287 | Val loss: 0.1282 | Val acc: 0.9688\n",
      "Epoch 100/100 | Train loss: 0.1281 | Val loss: 0.1276 | Val acc: 0.9688\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_model(\n",
    "    model,\n",
    "    train_X[:64], train_y[:64],\n",
    "    train_X[:64], train_y[:64],\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3e309d38-a6ab-4e12-a851-9df9cdac36f6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7278809e8fb5745693feb298ac86e088",
     "grade": true,
     "grade_id": "cell-829cf7e987433748",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### MANUALLY GRADED TASK\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    \"\"\"\n",
    "    Plots training and validation loss over epochs.\n",
    "\n",
    "    The plot should clearly show both curves and include axis labels\n",
    "    and a legend.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label=\"Train loss\", color=\"blue\")\n",
    "    plt.plot(val_losses, label=\"Validation loss\", color=\"red\")\n",
    "    return plt.show()\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f5e73ec4-1dc9-48cf-b471-acc1d5d9badc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2f52fedcc0ae4e78b8657e3810bf4e5",
     "grade": false,
     "grade_id": "cell-c5b83ae71a0c012c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAGsCAYAAACb7syWAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASDpJREFUeJzt3Qd0VVXaxvEnvQAJKYTQOwIivYhdQXHEhmVwxoKK+IkNwbGgI1hGwTo2FMUGogOKih1hsCAjUkUQECkCoSQkJCQhvdxv7X1IIEoJEG79/9Y6c3uyc84En+zy7iCXy+USAAAA4AbB7vgmAAAAAOETAAAAbkXPJwAAANyG8AkAAAC3IXwCAADAbQifAAAAcBvCJwAAANwmVD6gvLxc27ZtU506dRQUFOTp5gAAAOAPTOn43NxcNWzYUMHBwb4dPk3wbNKkiaebAQAAgENISUlR48aNfTt8mh7Pih8mJibG080BAADAH+Tk5NjOworc5tPhs2Ko3QRPwicAAID3OtQUSRYcAQAAwG0InwAAAHAbwicAAADchvAJAAAAtyF8AgAAwG0InwAAAHAbwicAAADchvAJAAAAtyF8AgAAwG0InwAAAHAbwicAAADchvAJAAAAtyF8AgAAwG0In/vx8cfS8uXuuwgAAACBgvD5B7NnS5ddJp11lvTzz565KAAAAP6K8PkHPXtKXbtKO3c6AXTZMs9cGAAAAH9E+PyDunWd3s9evaTMTCeALl3qmYsDAADgbwif+xEbK82aJfXuLWVlSf36EUABAABqAuFzfz79VLHF6TaA9unjBNC+faUlS2rknAMAAAQswucfrV0rXX651K6dYj6apJlfunTSSdKuXU4ANYEUAAAAR4bw+UdFRTZ42gmf116rmEv66avx63TyyVJ2ttS/v3T++dLq1Ud4xgEAAAIY4fOPOnaUFi2SnnhCioqSvv5atfucoDn9xuqOW0oUGip9/rl0wgnSzTdLO3Z45LoBAAD4JMLn/oSFSXfdJf3yi3T22VJhoSIeuk//nttd6/6zSBdfLJWVSS+/LLVuLY0bJxUXu/3aAQAA+BzC58G0bCl99ZU0ZYqUmCitWKFmg07UR+3v03ezitS9u5SbK40aJZ14orRypduuGwAAgE8ifB5KUJB05ZXOJE9zW14ujR2r00Z018KXFmvyZCkhQfrpJ9kw+vTTTq8oAAAA/ozwWV2m59P0gH70kZSUZLs5g086UVev+adWLC7SgAHOWqV//MMpTL9xY7W/MgAAQMAgfB4uM+HTjK9fcYXTxfnoo2pwYU99+s8FmjhRql1bmjvXWZBkHpuOUgAAADgIn0faC/qf/0jTp0v16tm5oEEn9dENP92i5fOydcop0u7d0o03Ott0/vDDEX0XAAAAv0P4PBqXXur0gg4eLLlc0ksvqcW57fTdzdP0zNMuxcQ4uyKZGqFmuuiWLTV23QAAAHwS4fNomZ7Pt96y9UDVtq2Umqrgv1+hEbPP0/rZG3TDDc6apXfflY47TvrXv6SCghq5dgAAAD6H8FlTzjxTWr5cevBBKTxcmjlTiae008Swm7Xssy229zM/X3rgAaeC07PPEkIBAEDgIXzWpIgIacwYJ4Sa4vQlJbYSfaeBrfR951s1Y/xWNW1qO0c1YoTUooX0zDNOKAUAAAgEhM9jwYyvz5olffutdPrpdvujoJfG66KRrbThguGa/ESqmjWT0tKkO+90QqipD8pwPAAA8HeEz2PJBE8TQM18ULMEvqhIIeOf19UPttL6vz+gt57PUfPmzv7wpj5omzbSG29QpB4AAPgvwqe75oOa4p+zZ0u9e9tx9pCx/9Lgh1tp3W3P6Y2Xi+xw/Nat0pAhUufO0qefOgvoAQAA/Anh013Mkvd+/aT586UPP3SG5jMyFHLnHbru8XZa++AUPfVEueLinOpNF17odJz++KPbWggAAHDMET49EUIHDpR++UV69VWpQQO7F2f49Vfrzul9tPG9hbrnHikyUvr+e6lPH+naa535oQAAAL6O8OkpoaHS0KHSunXSY485+3IuXKiYs3trXPoQrZ+/w4ZOY9Ikp4Toc89JpaUeazEAAMBRI3x6WnS0NGqU9Ntv0tVXO8+98YYantFWb3Z5Tgvmlah7dyknR7rjDqlrV+m77zzdaAAAgCND+PQWZvh98mTpf/+TunWTsrNt2ux1UzcteOZ/euUVKT7eGa0/4wzpqqucVfIAAAC+hPDpbU46yQ6/27SZkGDTZsjpp+jGxTdq7YJMDRvmTBt95x2pXTvptdek8nJPNxoAAKB6CJ/eKCREuvFGac0ap/aSMXGi4k9ur5dOeVcLF7js8HtWljNt1KyKX7XK040GAAA4NMKnNzM9n6Zr09QIbd/eGWe/8kr1uO8cLfzPers1Z61a0rx5Upcuzr7xhYWebjQAAEANh8/x48erefPmioyMVO/evbXQDBMfxK5du3TLLbeoQYMGioiIUNu2bfXFF18cybcOTKeeKi1bJv3rX87+8f/9r0K7ddKIsBe1ckW5zj/f2UbevNyjh/TTT55uMAAAQA2Fz2nTpmnkyJEaM2aMli5dqs6dO6t///7acYDVL8XFxTr77LO1ceNGTZ8+XWvWrNHEiRPVqFGjw/3WgS08XLr/fmfFkdkxKT9fuu02NbvhbH3ywiZNny4lJTkF6s0mSqZ6E2WZAACAtwlyuQ5vE0fT09mzZ0+9+OKL9nF5ebmaNGmi2267Tffee++f3j9hwgQ9+eST+vXXXxUWFnZEjczJyVFsbKyys7MVExNzRF/Dr5gVRi+9JN19t1RQINWpIzMGn37hEN00LMhuoGSceKKzgN7sGQ8AAHAsVTevHVbPp+nFXLJkifqZbSIrvkBwsH0832wbuR+ffPKJ+vTpY4fd69evr44dO+qxxx5TWVnZAb9PUVGR/QH2PbDvVQuWbr1V+vlnZ3V8bq5deVTv2gGa/mKqDZzmmputOc1c0JdfZp94AADgHQ4rfGZkZNjQaELkvszj1NTU/X5mw4YNdrjdfM7M83zggQf09NNP619mguIBjB071ibnisP0rGI/TJemWYz01FPOXNAvv1RQt666utlcrVghnXWWMzp/881OXVBzHwAAwK9Xu5th+aSkJL366qvq3r27Bg0apPvvv98Oxx/IqFGjbJdtxZGSknKsm+nbZZnuvFNaulTq2FEyfwScdZaavveUZs9y2RXxZifPd9919onfsMHTDQYAAIHssMJnYmKiQkJClJaWVuV58zg5OXm/nzEr3M3qdvO5Cu3bt7c9pWYYf3/MingzV2DfA4fQoYMzzn7llZKZ0nDXXQr+62UacX225sxxFiMtX+6shp85k7MJAAB8IHyGh4fb3ss5Js3s07NpHpt5nftz8skna926dfZ9FX777TcbSs3XQw0yRT/ffttZjGQWd5mVRz176rS4FVqyxFkFbwrTn3eesxr+8JaaAQAAeGDY3ZRZMqWSJk2apNWrV2vYsGHKy8vTddddZ1+/5ppr7LB5BfN6Zmamhg8fbkPn559/bhccmQVIOAbM3ptmD05Ted7MlV271i57b7zsM333nbMjkgmdpmrTX/9KUXoAAOBeoYf7ATNnMz09XaNHj7ZD5126dNHMmTMrFyFt3rzZroCvYBYLffXVVxoxYoQ6depk63uaIHrPPffU7E+Cqnr1cuaB/u1vtii9Lr5YERMm6NVXbzCdoXaxvKkNmp4uzZgh1a3LCQQAAF5Y59MTqPN5FMzWR2af+Lfech4/+KA0erS++TbI5FGZKladOtmF8mrYsIYuGAAACDg5x6LOJ3yQmfv5xhvOOHtF+LzxRp15aqkdhjfrxMxCJFMu9LffPN1YAADg7wifgTIP1NRVNdXmzZSI116TBg5UlzZ5+uEHqXVradMmszhMWrjQ040FAAD+jPAZSG66yVkBHxkpffaZ1K+fWsRn63//c0owZWQ4henNFFEAAIBjgfAZaC66SLbwZ1ycUxe0Xz8lhWbq66+ls8+W8vKk88+nFigAADg2CJ+ByEzw/OYbs2uAtHix1Lev6hRl2M5Qk02Lipzbzz/3dEMBAIC/IXwGqs6dnQBqSmQtWyadeabCd+3Q++9Ll14qmc2nBg6UPvnE0w0FAAD+hPAZyMxe8N9+a/ZAlX75RTrjDIVlbNd//uMUoDdVmkwQ/egjTzcUAAD4C8JnoGvXTrbmUuPG0urV0umnKyxti955R/r736XSUunyy2V7RAEAAI4W4RNSmzbS3LlSs2bOdpx9+yo0I1WTJ0tXXy2VlTkbJRFAAQDA0SJ8wtGihdMDagKoqTbft69CMtP15pvStdfuDaAMwQMAgKNB+MReJniaMkyNGkmrVknnnKOQnCxbk76iB9TMBWUREgAAOFKET1TVqpUTQCtWwZ97rkLycmwPqOn5NHNAL7tM+uILThwAADh8hE/82XHHOdscJSQ4+22ed55CCnbbOaBm8ZFZBX/JJdJXX3HyAADA4SF84sBlmGbNkmJjZfffvPBChZYU2FXwJniaQvQXX8xWnAAA4PAQPnFg3bo53Zu1azsF6QcNUphKbB3QCy6QCgttJrUL5QEAAKqD8ImD693b2WczMlL69FPp+usVHlpuyy6dd55UUCANGCDNn8+JBAAAh0b4xKGddppT5DMkRJoyRbrjDkWEu/TBB1K/ftLu3XZdkt0mHgAA4GAIn6ie88+XJk2SgoKkF16QHnrIdobOmOFk05wcW5lJP//MCQUAAAdG+ET1XXmlEzyNhx6SnntOtWpJn30mnXiilJUlnX22UyIUAABgfwifODy33CI98ohz/447bG9onTrSl19K3btL6el2cyS7SRIAAMAfET5x+O6/Xxoxwrk/ZIhdiFS3rrMwvlMnKTVVOussad06Ti4AAKiK8InDZ+Z9PvWUNHjw3j035861Nelnz5Y6dJC2bpXOPFNav54TDAAA9iJ84sgEB8tu+m4WIlUU/Pz5ZyUlSV9/LbVvL23Z4gTQ33/nJAMAAAfhE0cuNFR67z3plFOk7Gyn3tKGDXZbeBNAzS6dKSlOAN24kRMNAAAInzhaUVFO8fmKyZ5muXtqqpKTnU2R2raVNm1yAqi5BQAAgY2eTxw9s9po5kypZUvb82l7QHftUoMGTg9o69ZOzycBFAAAED5RM0zSnDVLdszdVJo3c0Dz89WokdMD2qqVM/fz1FOltWs56QAABCrCJ2qOSZimBzQmRvr+e+nyy6XiYjVuLH33ndSunTMH1ATQX37hxAMAEIgIn6hZXbpIn3/uzAX94ovKckymB9QE0M6dpbQ06fTT2QseAIBARPhEzTOr3z/8UAoLk6ZOdXZFcrlsGSYzBN+7t5SZ6RSinzePCwAAQCAhfOLYMIuOpkxxCtK/8op033326bg4pxC96fnMzZXOOcd5DAAAAgPhE8eO2fnIBE9j3DjpiSfsXbMXvBmRN/m0oMBZm7RsGRcCAIBAQPjEsTV0aGXo1D33SG+/be9GR0szZkj9+zsbJF16qZSVxcUAAMDfET5x7N11l3T33c79G26QfvzR3o2IkN59V2rRwikPetVVUnk5FwQAAH9G+IR7jB0rXXSRLb2kiy92ai5Jio+XPvhAiox0huIfeYQLAgCAPyN8wk3/Twt2FiCdcIJTa8kE0Px8+1LXrtKECc7bHnrICaEAAMA/ET7hPrVrS598IiUmSkuXStdea0swGaYc6LBhzsMrr3SG4QEAgP8hfMK9mjffWwP0/ferjLP/+99ODdBdu6RLLqnsGAUAAH6E8An3M/trvvyyc3/MGGfS554FSNOnS/XqOdvDm3VKAADAvxA+4RlDhkh33KHKMXczD1Sy+8C/847z9KuvSps3c4EAAPAnhE94zpNPSj16SHl50uOPVz599tnO1pulpc5bAACA/yB8wnNCQ6V//cu5b4bht22rfOn++53biROl1FQPtQ8AANQ4wic8y2zufvLJzjZHjz1W+fSZZ0p9+khFRdLTT3u0hQAAoAYRPuFZQUF7V7ybbs49kzzN0//8595O0YwMD7YRAADUGMInPM90c5rD7H5UMQwv6S9/cQrQmymhzz3n0RYCAIAaQviEd6jo/XzzzcoK8/v2fj7/vFP/EwAA+DbCJ7yDmffZv7+zxP3hhyufNrtwdugg5eRI48d7tIUAAKAGED7hPSpC59tvS2vWVG4JX7Hy3eyAZIbgAQCA7yJ8wnv06iVdcIFUXi499FDl03/9q9S6tbRzp/TKKx5tIQAAOEqET3hn7+fUqdIvv1SWAx01ynnaFJ03VZkAAIBvInzCu3TpIl16qeRySQ88UPn0VVdJTZs6BecnT/ZoCwEAwFEgfMI7ez/NZM8ZM6S5c+1T4eHS8OF793wHAAC+ifAJ72OWtw8d6ty/805nDqikwYOdELpkiXMAAADfQ/iEdzILjurUkRYvlt591z6VkCBddpnzMr2fAAD4JsInvFP9+ntXGZnb/Hx798YbnadMHs3N9WD7AADAESF8wnvdcYezymjLFqfIp6TTTpPatpV273YWxAMAAN9yROFz/Pjxat68uSIjI9W7d28tXLjwgO996623FBQUVOUwnwMOKSpKGjfOuW9uU1PtlpsVvZ8MvQMAEADhc9q0aRo5cqTGjBmjpUuXqnPnzurfv7927NhxwM/ExMRo+/btlcemTZuOtt0IFFdc4RSfN12do0dXWXhkpoMuXerpBgIAgGMaPp955hkNHTpU1113nTp06KAJEyYoOjpab7zxxgE/Y3o7k5OTK4/6Zj4fUB2mq/OZZ5z7r78urVihxETpkkucpyZO5DQCAOC34bO4uFhLlixRv3799n6B4GD7eP78+Qf83O7du9WsWTM1adJEF110kVauXHnQ71NUVKScnJwqBwLYySc7y9xNySVTesnlqhx6f+cdp1MUAAD4YfjMyMhQWVnZn3ouzeNUs/XMfhx33HG2V/Tjjz/WlClTVF5erpNOOklbzCKSAxg7dqxiY2MrDxNaEeDMnE8z1j57tl39fkavfLvfu1nxPm2apxsHAAC8ZrV7nz59dM0116hLly46/fTT9eGHH6pevXp65ZVXDviZUaNGKTs7u/JISUk51s2Et2vVam/ppccfV1DH4zXulM/sQxYeAQDgp+EzMTFRISEhSktLq/K8eWzmclZHWFiYunbtqnXr1h3wPREREXaR0r4HoDFjpA8/lBo3ljZu1KVvXaCPgy5W6sJNWraM8wMAgN+Fz/DwcHXv3l1z5sypfM4Mo5vHpoezOsyw/YoVK9SgQYPDby0Cm1l8NHCgtHq1dPfdUmioLnR9rNVqry1DH5K2bfN0CwEAQE0Pu5sySxMnTtSkSZO0evVqDRs2THl5eXb1u2GG2M2weYWHH35Ys2bN0oYNG2xppquuusqWWrrhhhsO91sDjtq17dC76e7M6nSaolWg8xc/qLJGTbSqxQB9d9v7Wrm0SKWlnDAAALxN6OF+YNCgQUpPT9fo0aPtIiMzl3PmzJmVi5A2b95sV8BXyMrKsqWZzHvj4uJsz+kPP/xgyzQBR+X44xW79Fs9cNxU9V8/Xqfof+qw8QvpxS+U+WKcXgv5u7aeeZWufL632rUP4mQDAOAFglwul0tezpRaMqvezeIj5n/ij8rKpFWrpHVf/qZa0yepy8+TlVS8t5rCJjXV6uMv1wn/+qsaXdTTGb4HAAAeyWuET/ifsjKVz56jrGcnKfq/nyiqbG8h0J21myn8mitU5/F/OsP3AACgRhA+AaOgQGtfmKkt/35PPVM/VW3l2adnJ12pb2+YYuvXm7VycXGcLgAAjgbhE/iDebPy9d1t0zXqt2sVLJdO1jz9oJPta8cfL116qfTAA3YRPQAAOEbh85gXmQe8xSnnROu+X69RzuVOpYV342/Vca3L7H2z4+vDD0sTJni4kQAA+DnCJwKKWWtUd/yjUt26apa5TL/eOVFmz4TRo53Xze3OnZ5uJQAA/ovwicBTr57TzWncf7+SQjPtcPsJJ5jSYHuDKAAAqHmETwSmYcOctJmZaSd6mnmezz3nvGSG3les8HQDAQDwT4RPBCaTNl94YW/a/PlnnXmms+iovFwaPlzy/gq4AAD4HsInAtfpp5stu5y0edttNm0++aQUESF984300UeebiAAAP6H8InAZtJmdLT0/ffS1Klq0UK66y7npTvvlAoLPd1AAAD8C+ETga1JE+m++5z7//iHtHu37r1XatRI2rhReuYZTzcQAAD/QvgETBdny5bStm3SI4+oVi3p8ced0/LYY9LWrZwiAABqCuETiIyUnn/eOQ+mq3P1av3979JJJ0l5edI993CKAACoKYRPwBgwQLrgAqm01C4+CpLLll4yRenfeUf6+mtOEwAANYHwCVQwadP0gs6ZI02frh49nHKgxk03sfgIAICaQPgEKpil7ma1kTFihF18ZOZ8JidLa9dKY8dyqgAAOFqET2Bfd9/tLD4yq4z+9S/Fxu6dDmrC56+/croAADgahE9gX1FRe/fZfPppmzYvu8yZElpSIv3f/7HzEQAAR4PwCfzR+ec7xz6Lj1580alFP3eu9OabnDIAAI4U4RPYH9P7afbZ/O9/7eKj5s2lhx7aW4t+xw5OGwAAR4LwCeyPmfdZsfho+HApM9PedO4sZWU5ARQAABw+widwIKa6/HHHSdu3S7ffrrAw6ZVXnNqfb7/tdIoCAIDDQ/gEDrb4aNIkKTjYqTT/wQfq3Vu6+Wbn5aFDpdxcTh8AAIeD8AkcjEmbFcPvptJ8WpotudSsmbRxo3TXXZw+AAAOB+ETOJQxY5zJnhkZNoDWqe3SG284L5lh+FmzOIUAAFQX4RM4lPBwafJk2UmfM2bYCZ9nnSXdcovz8pAhUnY2pxEAgOogfALV0anT3lpLt98upaTo8celVq2kLVukkSM5jQAAVAfhE6guM8HzxBOdbs4hQ1Qr2mULzpvV72YY/vPPOZUAABwK4ROortBQZ/W7WQU/e7Y0YYJOPVW64469q99NDVAAAHBghE/gcLRtK40b59y/+2675P3RR52nTTlQU4geAAAcGOETOFy33irb5bl7t+3ujIp0VZYDNcXnP/uMUwoAwIEQPoHDZVLm669LkZHONkevvWanglYsOjKr4PPyOK0AAOwP4RM4Em3aSI895ty/8067+v3BB53i85s3y94HAAB/RvgEjpQpudSnj7PH5o032tXvL73kvPTvf0vLlnFqAQD4I8IncKRCQpwaSxER0syZdiX8eedJl18ulZVJ//d/zi0AANiL8AkcjXbtpIcfdu6bmktbt+rZZ6WYGGnhQluNCQAA7IPwCRwts9KoZ0+n+PxNN6lhA1fldNBRo6Rt2zjFAABUIHwCNVF83mx1ZPaAN3WW3nvPZFD16uVMB6X2JwAAexE+gZpw/PHSffc590eOVEh+rl55xZkWOn06tT8BAKhA+ARqyj33SC1bOuPsDz+sLl2kESP21qUvKOBUAwBA+ARqiik6//zzzn2z6mjlSlvvs0kTadMm6amnONUAABA+gZo0YIB00UVSaant7jS1P594wnlp7Fhbix4AgIBG+ARqmun1NL2g334rTZ2qQYOkk092ht3vvZfTDQAIbIRPoKY1by7df79z/847FZSbo+eek4KCpHfflX74gVMOAAhchE/gWLjrLql1a2n7dumhh9S9u3T99c5LpvRSeTmnHQAQmAifwLFgttx84QXnvun2XLFCjz4q1akjLV4sTZ7MaQcABCbCJ3CsnHuudMklzgbvt96q+kkujR7tvGTmfubkcOoBAIGH8AkcS//+t7P4aO5c6euvdfvtUps2UlqaKrfgBAAgkBA+gWOpaVNp6FDn/iOP2B04n3lmby5dv57TDwAILIRP4Fi7+25n3/fvvpO+/96WAu3fXyou3rsoHgCAQEH4BI61xo2l665z7j/yiC25VFF4/v336f0EAAQWwifgDmaFUWioNHu2tGCBOnWS/vIXp+QS224CAAIJ4RNwV+H5q6927j/yiL255x7n4ZtvOguQAAAIBIRPwF3uu08KDpY+/1xaulSnnSb17i0VFe0tCQoAgL8jfALuYnY8+tvfnPuPPmrnflb0fo4fL+XmcikAAP6P8Am4u/fTpM4PP5R++UUXXii1bSvt2iVNnMilAAD4P8In4E4dOkiXXurcf/RRhYQ428Abpv6nKb8EAIA/O6LwOX78eDVv3lyRkZHq3bu3Fi5cWK3PTZ06VUFBQbr44ouP5NsC/uGf/3Rup02T1qyx65AaNJC2bpXefdfTjQMAwMvC57Rp0zRy5EiNGTNGS5cuVefOndW/f3/t2LHjoJ/buHGj/vGPf+jUU089mvYCvq9zZ9nxdpdLGjdOERHSHXc4L5n6n6b8EgAA/irI5TL/Baw+09PZs2dPvfjii/ZxeXm5mjRpottuu033mlqG+1FWVqbTTjtN119/vb7//nvt2rVLM2bMOOD3KCoqskeFnJwc+z2ys7MVExNzOM0FvNOCBdKJJzo7H23apOyoZLsTZ06O9PHHTjYFAMCXmLwWGxt7yLx2WD2fxcXFWrJkifr167f3CwQH28fz588/4OcefvhhJSUlaciQIdX6PmPHjrWNrzhM8AT8iqmxdNJJziTPl15SbKw0bJjz0uOPe7pxAAAcO4cVPjMyMmwvZv369as8bx6npqbu9zPz5s3T66+/romHsZR31KhRNjVXHCkpKYfTTMA3jBjh3L78slRQoOHDnY7QH36QZs70dOMAAPDB1e65ubm6+uqrbfBMTEys9uciIiJsd+2+B+B3zMI7s/NRRoY0ZYpddPR//+e8NHiwtG2bpxsIAICHw6cJkCEhIUr7w16A5nFycvKf3r9+/Xq70OiCCy5QaGioPSZPnqxPPvnE3jevAwHL7PV+++3O/X//2y5AGjdOdt93s35v0CCppMTTjQQAwIPhMzw8XN27d9ecOXMqnzMLjszjPn36/On97dq104oVK7Rs2bLK48ILL9SZZ55p7zOXEwHPzIOuU0davVr66itFR0vTpztPzZsn3X9/wJ8hAECgD7ubMktmGH3SpElavXq1hg0bpry8PF133XX29WuuucbO2TRMHdCOHTtWOerWras6derY+ybMAgHNTCm54Ya9VeYltWkjvfmm89STTzqr3wEACNjwOWjQID311FMaPXq0unTpYnswZ86cWbkIafPmzdq+ffuxaCvgn8zQe3CwNHu23XLTMJsgVdT+NPM/N2zwbBMBAPBYnU9vrhsF+KzLL3fG26+/Xnr9dfuUqcJ0xhmSqWLWrZv0v/+Z0QRPNxQAADfW+QRwjMsuvfOOWcFn75pZKWYHzoQEaenSvW8BAMCXET4Bb2AW7JnC82ZnL1P3cw+zv4LJo8aECRIzWgAAvo7wCXiDoKC9XZsvvSQVFla+1L+/sx28YVbAAwDgywifgLcwq4zMBu/p6dIHH1R56dRTndu5cz3TNAAAagrhE/CmovPXXuvcf++9Ki+ddppz+/33HmgXAAA1iPAJeJPLLnNuv/rKLBv8U8/n8uXSrl0eahsAADWA8Al4k44dpeOOcxYeffZZ5dNm91pTfN4URjMllwAA8FWET8DbFh6Zmp/G++9XeYl5nwAAf0D4BLx16P3LL6Xc3MqnmfcJAPAHhE/A23Tq5Iyxm6H3zz//U/hctEjKz/dc8wAAOBqET8BHht6bN5caNZJKS6UFCzzXPAAAjgbhE/DmofcvvpB2767MpBW9n9T7BAD4KsIn4I26dJFatXJ2Otpn6L1i0RH1PgEAvorwCXj70Pv06ZVPV/R8zp8vlZR4qG0AABwFwifg7UPvpuczL8/ebd9eio93FhwtXerZ5gEAcCQIn4C36tZNatFCKihw5n6aX9hg6n0CAHwb4RPwsVXvzPsEAPgywifgK0Pve4p7Vsz7nDdPKi/3YNsAADgChE/Am/Xo4RT4NMHT7HgkqWtXqVYtKStLWrnS0w0EAODwED4Bbx96r+j93DP0HhoqnXSS8xT1PgEAvobwCXi7ivD52WeVq96Z9wkA8FWET8Db9eoltWzpBM89NT/33enI5fJs8wAAOByET8AXht6vv965//rrlXk0LEzavl3asMGzzQMA4HAQPgFfcO21TpFPs6/mb78pKsoJoAbzPgEAvoTwCfiCRo2kc8917r/xRpV5n4RPAIAvIXwCvmLIEOd20iSptFRnn+08/PBDafduj7YMAIBqI3wCvuL886V69aTUVLvd5hlnSG3aSDk50ttve7pxAABUD+ET8BXh4dI11zj3X3/dTgG99Vbn4YsvsuodAOAbCJ+ALw69m+02t2+365Bq15ZWrZK+/trTjQMA4NAIn4Avad9e6tNHKiuTJk9WTIw0eLDz0gsveLpxAAAcGuET8NXeT7Pq3eWqHHr/9FNp40aPtgwAgEMifAK+5q9/lWrVsvU+NW+e2rWTXfleXi699JKnGwcAwMERPgFfU6eONGhQlR2PbrvNefjaa1J+vgfbBgDAIRA+AV8een//fVtr6bzzpBYtpKws6Z13PN04AAAOjPAJ+CKz6MiMt5tuzqlTFRIi3XLL3oVHLpenGwgAwP4RPgFfFBS0t/dzwgSbNq+/XoqOllasYMtNAID3InwCvuq665y0+dNPtshnXJx01VXOS5RdAgB4K8In4KsSEmS7O40nnqiy8GjGDCklxYNtAwDgAAifgC8bOVJ2n81Zs6Sff1bHjtKZZzo16M3KdwAAvA3hE/BlZon75Zc795980t4MHeo8nDzZqf0JAIA3IXwCvu6uu5zbqVOlTZt08cWy226a3Y7mzvV04wAAqIrwCfi67t2ls85yxtqffVZRUXtr0L/1lqcbBwBAVYRPwB/cfbdzO3GirTR/7bXOw+nTpd27PdoyAACqIHwC/uCcc6ROnaS8PFv309Sgb9PGefjBB55uHAAAexE+AX8pOl8x9/O55xRUVKjBg52HDL0DALwJ4RPwF2aiZ5MmUlqaNGWKrr7ayaTffiv9/runGwcAgIPwCfiLsDBpxAjn/lNPqWnjcvXt6zx8+22PtgwAgEqET8Cf3HCDFBsrrVkjfflllaF3an4CALwB4RPwJ3XqSJdc4txfskQDBzpPmWH3efM83TgAAAifgP8x8z6NbdtUq5b01786D1l4BADwBvR8Av6mYUPndvt2e1Mx9P7++07pJQAAPInwCfhr+Ny2zd6ccorUsqVTbP7DDz3bNAAACJ+Av2nQoErPpym3VLHjEUPvAABPI3wC/trzmZrq7Pcu6ZprnKe+/lrascODbQMABDzCJ+BvkpKk4GAneKan26eaNZOaNnVe3rDBs80DAAQ2wifgb0JDnQC6z9C70aiRc7t1q4faBQDAkYbP8ePHq3nz5oqMjFTv3r21cOHCA773ww8/VI8ePVS3bl3VqlVLXbp00dtstwK4ddGR0bixc7tlCycfAOBD4XPatGkaOXKkxowZo6VLl6pz587q37+/dhxgIll8fLzuv/9+zZ8/X8uXL9d1111nj6+++qom2g/gYIuOCJ8AAF8Pn88884yGDh1qA2SHDh00YcIERUdH64033tjv+8844wwNHDhQ7du3V6tWrTR8+HB16tRJ89huBXBbrU+DYXcAgM+Fz+LiYi1ZskT9+vXb+wWCg+1j07N5KC6XS3PmzNGaNWt02mmnHfB9RUVFysnJqXIAOAwMuwMA/CF8ZmRkqKysTPXr16/yvHmcasq6HEB2drZq166t8PBwDRgwQC+88ILOPvvsA75/7Nixio2NrTyaVGwXCOCIan3u2/PJnE8AgN+vdq9Tp46WLVumRYsW6dFHH7VzRr/99tsDvn/UqFE2sFYcKSkp7mgmEBA9n2a1u8vloXYBAAJe6OGcgcTERIWEhCgtLa3K8+ZxcnLyAT9nhuZbt25t75vV7qtXr7a9m2Y+6P5ERETYA0DNLTiqyKPFxWYUQ6pXj7MLAPDynk8zbN69e3c7b7NCeXm5fdynT59qfx3zGTOvE8AxUpE0zR+Ke3Y5Cg/fW/6TWp8AAJ/o+TTMkPngwYNt7c5evXrp2WefVV5enl39blxzzTVq1KiR7dk0zK15r1npbgLnF198Yet8vvzyyzX/0wDY/y5He0YmzNC7qYpm5n126cLJAgD4QPgcNGiQ0tPTNXr0aLvIyAyjz5w5s3IR0ubNm+0wewUTTG+++WZt2bJFUVFRateunaZMmWK/DoBjvMuRWQhoht73hE+z6GjpUhYdAQA8J8hl6h95OVNqyax6N4uPYmJiPN0cwDd07+4kzc8+kwYMsE/dfLNkBh3++U/pkUc83UAAgD+pbl5jb3fAX1HrEwDghQifgL+i1icAwAsRPoEArfUJAIAnED6BAKr1WRE+2eUIAOAphE/A33s+97PFZm6umRjuoXYBAAIa4RMIoGH32rWl2FjnPkPvAABPIHwC/j7svs8uR/v2fjL0DgDwBMInECi7HO3BoiMAgCcRPgF/3uVoz85jLDoCAHgLwifgz6j1CQDwMoRPwJ9R6xMA4GUIn4A/o9YnAMDLED6BAK31SaklAIAnED6BAB12NwvgCws91C4AQMAifAIBtuAoPl6KiPhTJgUAwC0In0CA9XwGBVHrEwDgOYRPIBB6PlNTq+xyVDH0zi5HAAB3I3wCgbDLUXl5lV2O2GITAOAphE8ggHc5YsU7AMDdCJ+Av6PWJwDAixA+gQCu9cmcTwCAuxE+AX/HFpsAAC9C+AQCsNZnRc+neWqfRfAAABxzhE8gAHs+k5OlkBAneKalea5pAIDAQ/gEAnDBkQmeFU8z7xMA4E6ETyAAFxwZLDoCAHgC4RMIlPB5gF2OqPUJAHAnwicQoLscscUmAMATCJ+AvzMTPPezyxHD7gAATyB8AoGAWp8AAC9B+AQCvNYnq90BAO5E+AQCwSF6Pl0uD7ULABBwCJ9AgNb6rMijhYVSZqaH2gUACDiETyBAa31GRkqJic59ht4BAO5C+AQCdNjdoNYnAMDdCJ9AgC44Mlh0BABwN8InEAgOscsRw+4AAHchfAKBtsvRkiWVTzPsDgBwN8InECi7HA0Y4NwfOFBKSbF3GXYHALgb4RMIFJMmSR06OIuOzjtP2rVLLVo4L/3wg7R2racbCAAIBIRPIFDExUlffCElJ0u//CJdcolO6VWsU0+Vdu+WLrtMKijwdCMBAP6O8AkEkmbNnABau7b0zTcK/b8hmvofl50Suny5dOutnm4gAMDfET6BQNO1q/T++8480ClT1PDlB/Tuu1JQkPTGG9Jbb3m6gQAAf0b4BALRuedKr7zi3H/0UfVd+bwefth5ePPNTi8oAADHAuETCFRDhkgPPODcHz5c96+9Vhf1y7PzPs38z5wcTzcQAOCPCJ9AIHvoIdvzaWqABk2epOkpvXRW8iq78v2GGySXy9MNBAD4G8InEMjMRM/77pPmzLGr4EPXrNKsXT11bcjbdlpo//7SrFmEUABAzSF8ApDOOENatkzq21chhfl6s+wavaYbtGB2tg2gJ5wgvfaaVFjIyQIAHB3CJwBH/frSV19JDz5oe0SH6HWlhjfVM2H3aOfK7Ro6VGra1Hk5PZ2TBgA4MoRPAHuZ8ktjxkizZ0vt2yuqOEcjSp5QSkhz/afWDYpLX2OniZoQOmyYtG4dJw8AcHgInwD+rG9fZxekTz6RTj5ZoWXFuiLvdf0a1F7f1B2oEwoXasIEqW1bZ2X8ggWcRABA9RA+ARzgX4dg6YILpHnznOPCCxXkcumMXTO0UL21LKGvznTN0QcfuHTiic60URYnAQAOhfAJ4NBOPln6+GNp1Spp8GApNFSdd36tOeqn9Ym9dWnIDM39rtwuTurVS/roI6m8nBMLAPgzwieA6mvf3tl/00z2NBvBR0aqZcYiTS8bqG3xJ+jasHf00+JSXXKJs0J+yhSptJQTDADYi/AJ4PA1aya98IK0aZNTJzQ2VsmZq/RmyVVKi2unWyJf19pVxbr6aievTp5MCAUAOAifAI5cUpKzQ5IJoeY2IUEJWev1YuENSo9trbujX9TWdfl2pL5DB+nttwmhABDojih8jh8/Xs2bN1dkZKR69+6thQsXHvC9EydO1Kmnnqq4uDh79OvX76DvB+CDYmOdHlATQp9+WmrQQLHZKXo8/zZlRDfV01H3K2/tVl1zjRNCTU9ocbGnGw0A8InwOW3aNI0cOVJjxozR0qVL1blzZ/Xv3187duzY7/u//fZb/e1vf9M333yj+fPnq0mTJjrnnHO0devWmmg/AG9Sq5Y0cqS0YYP00ktSixaKzt+pkQWPaXNwc70ffqVi1y6yPaFm5N7UDE1N9XSjAQDuFORyuVyH8wHT09mzZ0+9+OKL9nF5ebkNlLfddpvuvffeQ36+rKzM9oCaz19jukGqIScnR7GxscrOzlZMTMzhNBeAJ5WVObVCn31Wmju38ulFYSfpyZLh+lCXKDgsVJdfLt1+u/n3xaOtBQAchermtcPq+SwuLtaSJUvs0HnlFwgOto9Nr2Z15Ofnq6SkRPHx8Qd8T1FRkf0B9j0A+OiOSQMHSt99Jy1ZIjvuHhamniU/6D0N0pbwlhpR8ri+fDfT1go14XPaNOaFAoA/O6zwmZGRYXsu65s9oPdhHqdWc+zsnnvuUcOGDasE2D8aO3asTc4Vh+lZBeDjunWTJk1y5oWOHi3Vq6fk4hQ9rnu1PaSxXg2+SdkLf9UVV0itWjlTR7OzPd1oAIBPr3YfN26cpk6dqo8++sguVjqQUaNG2S7biiMlJcWdzQRwLDVo4Ez23LxZevNNqXNnRZQVaGj5K1oVdLymRgxWyOYN+sc/pMaNpREjJP4JAIAADZ+JiYkKCQlRWlpalefN4+Tk5IN+9qmnnrLhc9asWerUqdNB3xsREWHnCux7APAz5g/Qa6+VfvrJrEy023cGu8o1qGiy1oUcp6lxNyl29xY7XbRNG+nOO83oi6cbDQBwa/gMDw9X9+7dNWfOnMrnzIIj87hPnz4H/NwTTzyhRx55RDNnzlSPHj2OrsUA/EtQkHT66c72nYsWSeeeq+CyUg3KekWbwlprWqMRiivarmeekVq2lB5+WMrN9XSjAQBuG3Y3ZZZM7c5JkyZp9erVGjZsmPLy8nTdddfZ180KdjNsXuHxxx/XAw88oDfeeMPWBjVzQ82xe/fuI240AD9l/jj98ktnZfxppymkpEh/3fqstoY20+dxV+m43EUaM8aZE2p6RFmLCAABED4HDRpkh9BHjx6tLl26aNmyZbZHs2IR0ubNm7V9+/bK97/88st2lfxll12mBg0aVB7mawDAfp16qjMUP2uWdMopCi4t0XlZ72iRemlx5Mk6I/09/WNEqcxsH7OA3ry1vJxzCQB+WefTE6jzCQQ4U6bpueekqVOlkhL71PbQxnqz9Gq9rav1q9rbIXkzhdQUsG/a1NMNBoDAk1PNOp+ETwC+w5R0e/ll50hPr3z6p+BumlR+tabqCqUp2XacXnmldNlldrt5AIAbED4B+K/CQunTT6W333bmiJaW2qfLgkI0x3WWPtZF+kQXKjW0iVm/ZIPo+edLtWt7uuEA4L8InwACg+kBfe89J4guWFDlpaXqakOoCaOrwrrozLOCdMEFThA1e8sDAGoO4RNA4Fm7Vpoxwynb9MMP0j5T2repgWbqXHv8V/3U+IR4G0JNz6jZ2jM83KMtBwCfR/gEENhMj+jnn0uffCLXV18pKD+/8qUyBWuhetkgOltna3Wtnjqtb5jOOUf2aN3aKT8KAKg+wicA7DtHdN48aeZM51i5suo/mKqj73S67RE1R36zDjqrb5D69pXOOku2pBMA4OAInwBwIFu2SF99ZQ/X118raOfOKi9vV7K+1RmVR2j7turbL0hnnmlr37OCHgD2g/AJANVhqtMvWyb997/2cH3/vYJMT+k+zHxRE0JN7+j3OlUhx7fX6WcE2V1BzZGUxKkGgBzqfALAETDB06yaN9smffONXPPnK6i4uMpbMpSgeTrFBlFz5LftqhNPDTObMdnDbP/JnFEAgSaH8AkANaCgwAmj33wjff+9XD/+qCDz3D7yFaVF6qn56qMfdJLW1+ujdqfWU58+zkr67t2lqCiuBgD/RvgEgGPB9IKa7T6//94e5fP+p+BdWX962zq10gL1tqvql4b0krp0UbeTo9S7t9SzJyvqAfgfwicAuGvO6G+/OXVF589X+f9+UPDqVX96W4lC9bM6a7F62OO32t0V3aujuvUOs2G0Rw+pcWOG6wH4LsInAHhKVpa0aJG0cKFcCxeq/IcFCtm5409vK1SElquTlqi7lqqbNtbtqsgeHdWpV6S6dXOG681OTMwfBeALCJ8A4C3MTkubN9swqsWLVb54icoXLlbo7uz99pCuVnv9pK72WF+rs4K6dFarnvFm5N4e7duzIxMA70P4BABvD6Tr1zvzRxcvVtnSZSpf8pPCsqvWHK2Qosa2l9QM3a8K6aT8Vicopkdbdewapk6dZI/69eklBeA5hE8A8MVAagrg//STPcqXLlPJkp8VsfX3/b69SOH6Ve20QifYIyWmo8o7dFS97k11QqcgdewoHX+8FBvr9p8EQADKodQSAPiJnBxp+XJ7uJb9rOLFyxWy+heFFu7e79tzVVur1EErdbw90hKOlzp0UFL3Jjq+Y5ANpB06SDExbv9JAPgxwicA+Psq+02bpF9+kVasUOlPK1SybKXCf/9VIWUlhwylZl5pekJ7udq1V3y35mrfMcQGUjOfNCHB7T8NAD9A+ASAQFRSIq1bJ61caYNp8bKVKv15lSI3/6bg8tL9fsSsuv9Nbe0Qvjm21T5OZa3aKrLzcWp2QozatZOOO05q3lwKC3P7TwTARxA+AQBVQ+natdKqVTaYFv+8WiW//KqIjWsUWlJ1L/t9bVeyDaZr1Ubrgtsqt34bqU0b1e7cSi2Pj1Lr1vahrVEaHMwJBwJZDnM+AQCHVFbmDN//+qu02gTSNSpcvkah69coKjvtoB/drCZap9b22BjSWruTW9utm2p1aqUm7WrZYGr2uTe1SkNDuRaAv8shfAIAjkp2trN705o1cv22VgXL16r017WK2LxWEQV/rlG6r1TV13q1ssfGoJbKqddKZc1aKqJdCyUcn6xWbYLVsqXswcInwD8QPgEAx64kVEaGM7d03TqV/7ZO+cvXqWzNOkWkrFNkfuZBP27mmG5Uc21QS/2uFtoR1VyFyc0V1LyZIts1V70O9dS8RZCdY2p6TWvX5kICvoDwCQDwjF27nAL669erfN16FaxYr5Jf1ysk5XfVykxRsKv8oB/PV5Q2qZkNqOY2PbqZCpOaydWsuSLaNFXd9g3UtEWIDabmiI+nuD7gDQifAADvXPiUkiL9/rs9itb8rvzVm1S+YaMitm1UdPY2Bct18C+hUG1RY21WU3tsD22q/IQmKmvYRCHNmyj6uCZKaltXTZoGqUkTZzFUdLTbfkIgYOUw5xMA4HOKiqTNm51FUJs2qei3TcpftVHlv29S2PZNqpW1RSGuskN+md2qpRQ1sSHVHDsjG6sgobFKGzRRcPMmimzbTEmtY2wwbdTICajMPQWODuETAOCfq/O3b68MqCXrNytv9WaV/J6i4K0pispIUXT+zmp9qV2KtT2nZmjf3GZGNlJxYkObRsNbNFLtdo1Uv3WMGjYKsgG1YUOpVq1j/hMCPovwCQAITPn50pYt9nClbFHhui3KX7tFpRu3KGRbiqIzNiu64OCLoirkKVrb1LDyyAhvqILYBiqp11Bq0EDhzRooulUDJbaMUYOGQeYpe7BICoEoh2F3AAAOYPdup/d0z1G0drPy129T2aatCk7dqsjMbYouzKr26TOLpLargT1SlayMsAbKr5Os4oQGciUnK7RRsqJaJKtOqyTVbxSq5GTZo149KSSEqwT/QPgEAOBoe1DNEP+2bfYo/H278tdtU/HGrfb5sIztis7erqiig9c83Ve5gpShRBtQzZGmZOVG11dBbLJKE+orKLm+QhvVV1Tz+optlaikBiGqX98JqmZVP0EV3ozwCQCAu0JqaqoTVFNTnZC6fruKN6eqfNt2haZvV2R2mmrnpR2yzNS+yhRsg2qa6tsjXUnKjU5SYUx9lcQlSUlJNqhGNElSrRZJSmgcZXtSk5yXWOEPtyN8AgDgbYuldu6sDKpl29KU93uaCn9PVenWVCktTWE7UxWVk6bogp2HLDn1R7mqrR1KqjwyQ5NUUKueimKTVJ5QT0H1kxTaoJ4im9RT7Rb1lNgw3IbViiMi4pj95AgQOcz5BADAR5WWOrtIpaXZo3RrmvI3patgk7m/Q64dOxS6M00R2Ttsj2pYefFhfwuz2j9d9SqP7LBEFUQnqji2nsriExWUmKiQ5HqKaJSoqCaJim0So8R6QUpMlD1iY6Xg4GPy08NHET4BAAiU7U5zcqQdO+zhSk1TYUq68jfuUPHWdJWlpisofYfCsnYocne6ahVkVKtW6v6K+5tpABVHphK0OzJRhbUTVRyTIFdcglyJiQqrn6DwBgmKbpqoOo1jlZDoBNaEBCkujsDqz6obPkPd2ioAAFCzgoKcbkhztGmjIElRe479Ki93tkBNT3fCanqG06uakuGE1bQMKSNdobsyFJGboej8DEWW5ilMpXYtvzkqFe45Mvb/rUoVokzFa6cStFoJ9jY3IlFF0fEqrpOg0tgEueITFJKUoLD68YpslKBaTRNUt36EDavmMAutzA5V5seEfyB8AgAQSMxYuUl05jjuOBtWTe38g9bPLyhw5quawLpzp0q2ZygvZacKt2SoZFu6XOk7FZS5U6HZGYrYvdPOWTWBNVRlSrJLpdL3fq2iPUfWwXeoMkE1Q/FaowTtCo5XXmSCimrFq6ROvMpiExSUEK+QevE2tEY1TlB0ozjF1Q+v/NEIrd6L8AkAAA4uKsrZg9QcksIk1T3UOSssdALrnqMkbafyN+9U4dadKkndqTITWHfuVHB2psJzdyoqf6eiCzMVonLVVp49zN5TlikSkL/n2CfH7m/RlelpNaH1N8UrKzhB+ZHxtqfVhNbS2Hgpbm9ojWgQr+jG8YqtH1kltJoRY+azHjuETwAAUPMiI+1WpfbYE1hj9xw62JQAM3/VBNbMTLkydqpoe6byU5xbE2BdGZm2lzUkJ1PhuzMVVZCp6KIsWx2gjnbbY7+h9QBTAyo2CTCh1RybFa9ditPu8HgVmukBteNVGhMnV1y8guPjFJoUr/DkeEU1jFPthjGKSwi2gdXMZzW35sfGwRE+AQCAdzDdjXXrOkerVnZKgMlykdUpY5Wd7YTWrCy5dmY6oXVLpoq27VRpepbKTU9rVqZCTE/r7kxFmp7Woizb0xqtAkVrqxpr696vWbzn2HWQb6tgZSnOHimK18+KV05InPIj4lVcK07FdeLlinWCa0iiE1wjkuMqe1tNYK0IreZHDg2QVBYgPyYAAPBbZuunijFzswaruqHV9LTm5tpe1oqjJC1T+VuzbHgtTstUeUaWDbXB2VkKy81UeH6WnR4QUVZgg2uidtqjUln1pggUKNL2tJrgumrPbW5ovAqj4lRUK06ldeJVXjdOQXFxNriGJcUpsmG8ohvWVd16YZWh1dyatWa+tPsV4RMAAARuT2tFpYAWLapMDzgkswgrK8s5MjNVvjNLhdsyVbA1U8Wpmba31ZWZJe3KUmh2psLyshSZ70wRMKE1SoVqpG32qFRqJ646xz5FBQ40t9UE1k17bvPC4vYE1z3TBGLjFBQfp9bntNQFI1rLmxA+AQAAjmQRljkaNrQPTb396D1HtXpbs5zQao6yjCzlb3PCa0laln1spg6Y3taQ3CyF52U5c1tLcuyX+NPcVqNkz2Hesn3v0/M2D5VGvOpV15fwCQAA4Ine1ubN7VNmxLzOnuOQO1+Zua0VwTUrS6U7MlVggmtqlp0yYKYJmB5XE1xDczNVr1dLeRvCJwAAgC8IDXUq75uj4qlDBNf68j7sygoAAAC3IXwCAADAbQifAAAAcBvCJwAAANyG8AkAAAC3IXwCAADAbQifAAAAcBvCJwAAANyG8AkAAAC3IXwCAADAbQifAAAAcBvCJwAAANyG8AkAAAC3IXwCAADAbULlA1wul73NycnxdFMAAACwHxU5rSK3+XT4zM3NtbdNmjTxdFMAAABwiNwWGxt7wNeDXIeKp16gvLxc27ZtU506dRQUFOSW5G6CbkpKimJiYo7598OxwXX0D1xH/8B19H1cQ/+QcwwzjomUJng2bNhQwcHBvt3zaX6Axo0bu/37motC+PR9XEf/wHX0D1xH38c19A8xxyjjHKzHswILjgAAAOA2hE8AAAC4DeFzPyIiIjRmzBh7C9/FdfQPXEf/wHX0fVxD/xDhBRnHJxYcAQAAwD/Q8wkAAAC3IXwCAADAbQifAAAAcBvCJwAAANyG8AkAAAC3IXz+wfjx49W8eXNFRkaqd+/eWrhwofuuBg7b2LFj1bNnT7v1alJSki6++GKtWbOmynsKCwt1yy23KCEhQbVr19all16qtLQ0zrYXGzdunN1K94477qh8juvoG7Zu3aqrrrrK/r5FRUXphBNO0OLFiytfNwVWRo8erQYNGtjX+/Xrp7Vr13q0zaiqrKxMDzzwgFq0aGGvUatWrfTII4/Ya1eB6+h95s6dqwsuuMBubWn+/ZwxY0aV16tzzTIzM3XllVfanY/q1q2rIUOGaPfu3TXeVsLnPqZNm6aRI0fa+ldLly5V586d1b9/f+3YsaPGTzxqxnfffWeD5Y8//qjZs2erpKRE55xzjvLy8irfM2LECH366ad6//337fu3bdumSy65hEvgpRYtWqRXXnlFnTp1qvI819H7ZWVl6eSTT1ZYWJi+/PJLrVq1Sk8//bTi4uIq3/PEE0/o+eef14QJE7RgwQLVqlXL/jtr/riAd3j88cf18ssv68UXX9Tq1avtY3PdXnjhhcr3cB29T15ens0tphNtf6pzzUzwXLlypf3v6WeffWYD7Y033ljzjTV1PuHo1auX65Zbbqk8HWVlZa6GDRu6xo4dyynyETt27DB/mru+++47+3jXrl2usLAw1/vvv1/5ntWrV9v3zJ8/34Mtxf7k5ua62rRp45o9e7br9NNPdw0fPtw+z3X0Dffcc4/rlFNOOeDr5eXlruTkZNeTTz5Z+Zy5thEREa7//Oc/bmolDmXAgAGu66+/vspzl1xyievKK6+097mO3k+S66OPPqp8XJ1rtmrVKvu5RYsWVb7nyy+/dAUFBbm2bt1ao+2j53OP4uJiLVmyxHZDVwgODraP58+fX/OpH8dEdna2vY2Pj7e35pqa3tB9r2u7du3UtGlTrqsXMr3YAwYMqHK9DK6jb/jkk0/Uo0cPXX755XYaTNeuXTVx4sTK13///XelpqZWub6xsbF2ihP/znqPk046SXPmzNFvv/1mH//888+aN2+e/vKXv9jHXEff83s1fvfMrRlqN7/DFcz7TRYyPaU1KbRGv5oPy8jIsPNc6tevX+V58/jXX3/1WLtQfeXl5XaOoBn269ixo33O/LKFh4fbX6g/XlfzGrzH1KlT7XQXM+z+R1xH37BhwwY7XGumL9133332Wt5+++32d3Dw4MGVv3P7+3eW30fvce+99yonJ8f+oR4SEmL/2/joo4/aIVmD6+h7Uqvxu2duzR+N+woNDbWdOTX9+0n4hF/1mv3yyy/2L3T4lpSUFA0fPtzOMzKL/eC7fwCaXpPHHnvMPjY9n+Z30swxM+ETvuG9997TO++8o3fffVfHH3+8li1bZv+wNwtZuI6oCQy775GYmGj/wvvjKmjzODk5uUZONo6dW2+91U6O/uabb9S4cePK5821M1Mqdu3aVeX9XFfvYobVzcK+bt262b+0zWEWh5nJ8ea++euc6+j9zCraDh06VHmuffv22rx5s71f8W8p/856t7vuusv2fl5xxRW2WsHVV19tF/yZ6iIG19H3JFfjd8/c/nGBdWlpqV0BX9M5iPC5hxkW6t69u53nsu9f8eZxnz59avSko+aYedUmeH700Uf6+uuvbWmQfZlralbe7ntdTSkm8x9Drqv36Nu3r1asWGF7WCoO04Nmhvkq7nMdvZ+Z8vLHUmdm3mCzZs3sffP7af4jtu/voxneNfPJ+H30Hvn5+Xae375M54z5b6LBdfQ9Larxu2duTUeN6QyoYP67aq67mRtao2p0+ZKPmzp1ql359dZbb9lVXzfeeKOrbt26rtTUVE83DQcwbNgwV2xsrOvbb791bd++vfLIz8+vfM9NN93katq0qevrr792LV682NWnTx97wLvtu9rd4Dp6v4ULF7pCQ0Ndjz76qGvt2rWud955xxUdHe2aMmVK5XvGjRtn/139+OOPXcuXL3dddNFFrhYtWrgKCgo82nbsNXjwYFejRo1cn332mev33393ffjhh67ExETX3XffXfkerqN3Vgv56aef7GHi3TPPPGPvb9q0qdrX7Nxzz3V17drVtWDBAte8efNs9ZG//e1vNd5WwucfvPDCCzaohIeH29JLP/74Y42fdNQc8wu2v+PNN9+sfI/5xbr55ptdcXFx9j+EAwcOtAEVvhU+uY6+4dNPP3V17NjR/iHfrl0716uvvlrldVPy5YEHHnDVr1/fvqdv376uNWvWeKy9+LOcnBz7u2f+WxgZGelq2bKl6/7773cVFRVVvofr6H2++eab/f730PwxUd1rtnPnThs2a9eu7YqJiXFdd911NtTWtCDzPzXblwoAAADsH3M+AQAA4DaETwAAALgN4RMAAABuQ/gEAACA2xA+AQAA4DaETwAAALgN4RMAAABuQ/gEAACA2xA+AQAA4DaETwAAALgN4RMAAAByl/8HlVlI+rpJy/oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c4aff0c-97a5-4230-bf69-53fbb4807764",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b3af76ee4cb7bc383e4a22b51096bca",
     "grade": false,
     "grade_id": "cell-90d09e43d11ef81e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def evaluate_test(model, test_X, test_y):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model on the test set.\n",
    "\n",
    "    The function should compute and return the final classification accuracy.\n",
    "\n",
    "    Returns:\n",
    "    float: Test accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_X)\n",
    "\n",
    "        # Case A: outputs shape (batch, 2) -> CrossEntropy style\n",
    "        if outputs.ndim == 2 and outputs.size(1) > 1:\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            acc = (preds == test_y).float().mean().item()\n",
    "\n",
    "        # Case B: outputs shape (batch, 1) -> BCEWithLogits style\n",
    "        else:\n",
    "            probs = torch.sigmoid(outputs).squeeze(1)      \n",
    "            preds = (probs >= 0.5).long()                  \n",
    "            acc = (preds == test_y.long()).float().mean().item()\n",
    "\n",
    "    return float(acc)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b27a3e87-0be8-4b9a-8386-08a212b7bd8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5d33cb795b1b8602f6e9a0efcb273a6",
     "grade": false,
     "grade_id": "cell-9c2d7182ebbb1180",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_acc = evaluate_test(model, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3c7be74-2f8d-460b-8393-3a68f66daa14",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d1739c67f66e7af4ad6f472b311db40",
     "grade": true,
     "grade_id": "cell-b38d986b0242c0f4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##TEST\n",
    "assert isinstance(test_acc, float)\n",
    "assert 0.5 <= test_acc <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46fe8f46-575f-4331-ab4b-a12d98981013",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f6bba8ea039e5f09362a6859da85661",
     "grade": false,
     "grade_id": "cell-f2ed5609d39264c2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def cluster_movies(texts, true_labels):\n",
    "    \"\"\"\n",
    "    Performs unsupervised clustering on movie plot texts.\n",
    "\n",
    "    Requirements:\n",
    "    1. Convert the input texts into numerical features using TfidfVectorizer with max_features 20000, ommiting the english stopwords\n",
    "    and using ngram_range=(1, 2).\n",
    "    2. Apply dimensionality reduction to make clustering more effective.\n",
    "           Hint: use TruncatedSVD (a PCA-like method suitable for sparse text data).\n",
    "           The number of components should be 200 and the random state 42. \n",
    "    3. Cluster the reduced representations using KMeans with 2 clusters and random state 42.\n",
    "    4. Evaluate the clustering using the following external metrics:\n",
    "       - Adjusted Rand Index (ARI)\n",
    "       - Adjusted Mutual Information (AMI)\n",
    "       - Homogeneity\n",
    "       - Completeness\n",
    "       - V-measure\n",
    "\n",
    "    Important:\n",
    "    - The true labels must NOT be used during clustering.\n",
    "    - They are used only for evaluation.\n",
    "\n",
    "    Parameters:\n",
    "    texts (list of str): Movie plot descriptions\n",
    "    true_labels (array-like): Ground truth genre labels\n",
    "    n_clusters (int): Number of clusters\n",
    "    random_state (int): Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing all evaluation metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=20000,\n",
    "        stop_words=\"english\",\n",
    "        ngram_range=(1, 2)\n",
    "    )\n",
    "    X_tfidf = tfidf.fit_transform(texts)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "    X_red = svd.fit_transform(X_tfidf)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(X_red)\n",
    "\n",
    "    metrics = {\n",
    "        \"ARI\": adjusted_rand_score(true_labels, cluster_labels),\n",
    "        \"AMI\": adjusted_mutual_info_score(true_labels, cluster_labels),\n",
    "        \"Homogeneity\": homogeneity_score(true_labels, cluster_labels),\n",
    "        \"Completeness\": completeness_score(true_labels, cluster_labels),\n",
    "        \"V-measure\": v_measure_score(true_labels, cluster_labels),\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4116a2fd-edbf-493f-bd88-866e760f0217",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6c0e29073df0a1bd392ea13386caced",
     "grade": false,
     "grade_id": "cell-8f2953f551c29116",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "metrics = cluster_movies(\n",
    "    texts=df[\"Plot\"].values,\n",
    "    true_labels=df[\"Genre\"].astype(\"category\").cat.codes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cbb7ba2-1c4e-48c2-a242-16bc4f0eb17c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00150fd020998db6738a9cfc954592ba",
     "grade": true,
     "grade_id": "cell-8f335a84e705778d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##TEST\n",
    "assert isinstance(metrics, dict)\n",
    "for key in [\"ARI\", \"AMI\", \"Homogeneity\", \"Completeness\", \"V-measure\"]:\n",
    "    assert key in metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnp25 (Working Torch)",
   "language": "python",
   "name": "vnp25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
